<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LIGENE</title>
  
  <subtitle>Notes of Bioinformatics and Genomics</subtitle>
  <link href="http://blog.ligene.cn/atom.xml" rel="self"/>
  
  <link href="http://blog.ligene.cn/"/>
  <updated>2023-01-15T12:15:06.859Z</updated>
  <id>http://blog.ligene.cn/</id>
  
  <author>
    <name>adong</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>生物信息学课程视频</title>
    <link href="http://blog.ligene.cn/2023/01/14/bioinfoUCAS/"/>
    <id>http://blog.ligene.cn/2023/01/14/bioinfoUCAS/</id>
    <published>2023-01-14T09:55:51.000Z</published>
    <updated>2023-01-15T12:15:06.859Z</updated>
    
    <content type="html"><![CDATA[<p>中国科学院大学(UCAS)刘翟老师的生物信息学课堂实录视频。很棒的课程，建议1.5X倍速播放学习。</p><span id="more"></span><ul><li>【生信】第1讲 生物信息学历史、研究主题、核心问题和研究意义</li></ul><p><a href="https://www.zhihu.com/zvideo/1372131252246528000">https://www.zhihu.com/zvideo/1372131252246528000</a></p><ul><li>【生信】第2讲 生物信息学简史</li></ul><p><a href="https://www.zhihu.com/zvideo/1372282669938728960">https://www.zhihu.com/zvideo/1372282669938728960</a></p><ul><li>【生信】第3讲 生物数据库</li></ul><p><a href="https://www.zhihu.com/zvideo/1372686306892427264">https://www.zhihu.com/zvideo/1372686306892427264</a></p><ul><li>【生信】第4讲 GO数据库内容</li></ul><p><a href="https://www.zhihu.com/zvideo/1372848253055250433">https://www.zhihu.com/zvideo/1372848253055250433</a></p><ul><li>【生信】第5讲 序列比对</li></ul><p><a href="https://www.zhihu.com/zvideo/1374056173092659200">https://www.zhihu.com/zvideo/1374056173092659200</a></p><ul><li>【生信】第6讲 数据库搜索</li></ul><p><a href="https://www.zhihu.com/zvideo/1374325131284779008">https://www.zhihu.com/zvideo/1374325131284779008</a></p><ul><li>【生信】第7讲 系统发生与分子进化</li></ul><p><a href="https://www.zhihu.com/zvideo/1374669659606679553">https://www.zhihu.com/zvideo/1374669659606679553</a></p><ul><li>【生信】第8讲 基于距离矩阵的方法</li></ul><p><a href="https://www.zhihu.com/zvideo/1374773473613492224">https://www.zhihu.com/zvideo/1374773473613492224</a></p><ul><li>【生信】第9讲 最大似然</li></ul><p><a href="https://www.zhihu.com/zvideo/1374831038770860032">https://www.zhihu.com/zvideo/1374831038770860032</a></p><ul><li>【生信】第10讲 蛋白质结构与功能</li></ul><p><a href="https://www.zhihu.com/zvideo/1375749377638711296">https://www.zhihu.com/zvideo/1375749377638711296</a></p><ul><li>【生信】第11讲 NGS基因组学</li></ul><p><a href="https://www.zhihu.com/zvideo/1400533197780770817">https://www.zhihu.com/zvideo/1400533197780770817</a></p><ul><li>【生信】第12讲 基本算法总结</li></ul><p><a href="https://www.zhihu.com/zvideo/1400534557929771008">https://www.zhihu.com/zvideo/1400534557929771008</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;中国科学院大学(UCAS)刘翟老师的生物信息学课堂实录视频。很棒的课程，建议1.5X倍速播放学习。&lt;/p&gt;</summary>
    
    
    
    <category term="Bioinformatics" scheme="http://blog.ligene.cn/categories/Bioinformatics/"/>
    
    
    <category term="Teaching" scheme="http://blog.ligene.cn/tags/Teaching/"/>
    
  </entry>
  
  <entry>
    <title>浅谈Nanopore三代测序技术</title>
    <link href="http://blog.ligene.cn/2023/01/11/Nanopore/"/>
    <id>http://blog.ligene.cn/2023/01/11/Nanopore/</id>
    <published>2023-01-11T09:35:13.000Z</published>
    <updated>2023-01-12T23:56:45.829Z</updated>
    
    <content type="html"><![CDATA[<p>第三代测序技术与前两代测序技术相比，其最大的特点就是单分子测序，测序过程无需进行PCR扩增，实现了对每一条DNA分子的单独测序。其中，英国牛津纳米孔公司所开发的纳米孔（Nanopore）测序技术便是三代测序中的中流砥柱。2014年，其推出U盘大小的便携式MinION测序仪，仪器售价仅需$1000，据官网报道最长Reads可长达960Kb。从当前形势来看，一代测序因其准确度高，仍作为突变检测、单菌鉴定等的金标准而存在。以illumina HiSeq为代表的第二代短读长测序技术在测序市场上仍然占有绝对优势，主打低成本和高通量。但第三代测序技术（PacBio与Nanopore）近年来发展很快，主打长读长策略，直击二代测序短序列的软肋，已应用于基因组测序、甲基化研究和突变鉴定等多个研究领域。</p><span id="more"></span><h2 id="Nanopore测序原理"><a href="#Nanopore测序原理" class="headerlink" title="Nanopore测序原理"></a>Nanopore测序原理</h2><p>纳米孔测序，顾名思义，核心就是利用一个纳米孔，孔内共价结合有分子接头，将纳米孔蛋白固定在电阻膜上，然后使DNA双链解链成单链，再利用马达蛋白牵引核酸单链穿过纳米孔。当一条核酸链穿过纳米孔时，会对膜两边离子的稳定流动产生扰动，从而引起电阻膜上电流的变化。由于纳米孔的直径非常细小，仅允许单个核苷酸通过，而不同碱基的带电性质不一样，因此不同碱基通过蛋白纳米孔时对电流产生的干扰不同，通过实时监测并解码这些电流信号便可确定碱基序列，从而实现测序。纳米孔是对穿过的片段进行测序，而不管DNA片段的长度如何，而不是生成特定长度的序列，这可能是数百个碱基、或者更多个碱基的序列。Nanopore的长序列简化了重复区域的组装和测序，也提高了物种鉴定和宏基因组实验的速度。<br><img src="https://www.ligene.cn/images/blog/nanopore-1.jpg" alt="Nanopore-sequencing"></p><h2 id="Nanopore测序中的几种物质"><a href="#Nanopore测序中的几种物质" class="headerlink" title="Nanopore测序中的几种物质"></a>Nanopore测序中的几种物质</h2><ul><li>Reader（跨膜蛋白）：在自然界中，有一种可以嵌入到细胞膜中作为离子或分子通道的跨膜蛋白，具有天然的蛋白纳米孔。经过人为基因工程修饰后，得到Nanopore测序所需的Reader蛋白。</li><li>Membrane（电阻膜）：Reader蛋白会被嵌入到高电阻率的由人工合成的多聚物膜中，膜两侧是离子溶液，在两侧加不同的电位，离子就会在孔中流动，形成电流。</li><li>Motor（马达蛋白）：在Nanopore文库构建时，需要在接头上连接一种马达蛋白，用于将DNA或RNA分子推入纳米孔中。以DNA解螺旋酶作为 Motor为例，它除了可以解开双螺旋，使之变为单链，还可以提供推动力。</li><li>Tether：该蛋白用于锚定DNA或RNA链，防止其在溶液中飘动，并使其进入纳米孔中。<br><img src="https://www.ligene.cn/images/blog/nanopore-2.jpg" alt="Nanopore-sequencing2"></li></ul><h2 id="Nanopore测序的具体过程？"><a href="#Nanopore测序的具体过程？" class="headerlink" title="Nanopore测序的具体过程？"></a>Nanopore测序的具体过程？</h2><p>Nanopore测序是将人工合成的一种多聚物膜浸在离子溶液中，多聚物膜上布满了经改造的穿膜孔的跨膜通道蛋白（纳米孔），也就是Reader蛋白，在膜两侧施加不同的电压产生电压差，DNA链在马达蛋白的牵引下，解螺旋酶将双链DNA解开成单链；DNA单链分子通过一个孔道蛋白，孔道中有个充当转换器的蛋白分子；DNA单分子停留在孔道中，有一些离子通过带来电流变化，而不同的碱基带来的电流变化不同；转化器蛋白分子感受5个碱基的电流变化；根据电流变化的频谱，应用模式识别算法得到碱基序列。</p><p>Nanopore测序得到的序列文件的格式也是HDF5，下机产生后缀为Fast5的序列文件。Fast5文件可经由Poretools软件转换为Fastq文件或Fasta，然后进行后续数据分析。应用Poretools将fast5转换为fastq的示例：<a href="https://poretools.readthedocs.io/en/latest/content/examples.html#poretools-fastq">https://poretools.readthedocs.io/en/latest/content/examples.html#poretools-fastq</a></p><h2 id="Nanopore测序技术的主要优势？"><a href="#Nanopore测序技术的主要优势？" class="headerlink" title="Nanopore测序技术的主要优势？"></a>Nanopore测序技术的主要优势？</h2><ul><li>长读长：Reads可达Mb；适合进行大片段结构变异的检测或大基因组的拼接。</li><li>设备成本低：测序芯片可清洗再生，重复利用；</li><li>实时获得序列信息：最快可在1小时内完成测序流程及数据分析，满足动态检测宏基因组需求；</li><li>便携式测序装置：重量轻且占用空间小，可以随身携带随时测序；实时快速进行微生物分类鉴定。</li><li>直接测序：直接测序原始DNA和RNA，不需要进行PCR扩增，避免了扩增偏好性；保留了原始碱基修饰信息，能够直接读出甲基化的胞嘧啶。以往转录组分析由于无法直接对RNA进行测序，往往需要先对mRNA进行打断，再反转录为cDNA，无法获取和分析全长转录本。</li></ul><p>文字描述不容易理解，下面通过一个视频，更加直观的展示纳米孔测序。</p><iframe src="https://www.bilibili.com/video/BV1La41147dB/?share_source=copy_web&vd_source=d833801a2195b5684770ca2be2c47655" width="800px" height="600px" frameborder="no" framespacing="0" allowfullscreen="true" scrolling="no" sandbox="allow-scripts allow-same-origin allow-popups"> </iframe><!-- <video src="https://www.bilibili.com/video/BV1La41147dB?t=63.7" width="510px" height="498px" controls="controls"></video> -->]]></content>
    
    
    <summary type="html">&lt;p&gt;第三代测序技术与前两代测序技术相比，其最大的特点就是单分子测序，测序过程无需进行PCR扩增，实现了对每一条DNA分子的单独测序。其中，英国牛津纳米孔公司所开发的纳米孔（Nanopore）测序技术便是三代测序中的中流砥柱。2014年，其推出U盘大小的便携式MinION测序仪，仪器售价仅需$1000，据官网报道最长Reads可长达960Kb。从当前形势来看，一代测序因其准确度高，仍作为突变检测、单菌鉴定等的金标准而存在。以illumina HiSeq为代表的第二代短读长测序技术在测序市场上仍然占有绝对优势，主打低成本和高通量。但第三代测序技术（PacBio与Nanopore）近年来发展很快，主打长读长策略，直击二代测序短序列的软肋，已应用于基因组测序、甲基化研究和突变鉴定等多个研究领域。&lt;/p&gt;</summary>
    
    
    
    <category term="Genomics" scheme="http://blog.ligene.cn/categories/Genomics/"/>
    
    
    <category term="NGS" scheme="http://blog.ligene.cn/tags/NGS/"/>
    
  </entry>
  
  <entry>
    <title>An overview of TruSeq Stranded mRNA sequencing</title>
    <link href="http://blog.ligene.cn/2022/06/27/TruSeq-Stranded-mRNA-sequencing/"/>
    <id>http://blog.ligene.cn/2022/06/27/TruSeq-Stranded-mRNA-sequencing/</id>
    <published>2022-06-26T22:11:53.000Z</published>
    <updated>2023-01-15T12:20:49.365Z</updated>
    
    <content type="html"><![CDATA[<p>链特异性测序</p><span id="more"></span><h2 id="链特异性测序文库构建流程"><a href="#链特异性测序文库构建流程" class="headerlink" title="链特异性测序文库构建流程"></a>链特异性测序文库构建流程</h2><p>这里以TruSeq Stranded mRNA sequencing为例，介绍链特异性测序文库的构建流程，如图所示，红色始终代表sense strand的信息，天蓝色代表antisense strand的信息。<br><img src="http://www.ligene.cn/images/blog/Tru-Seq-library.png" alt="TruSeq Stranded mRNA sequencing libarry"></p><ul><li>首先，利用成熟mRNA带polyA尾的特点，通过oligo dT来富集mRNA；</li><li>接下来，使用超声波对mRNA进行片段化，然后再使用随机引物进行反转录，这个过程就是第一条链（天蓝色）的合成；</li><li>接下来，再使用RNaseH酶消化降解掉杂合链中的RNA，然后再进行第二链（红色）的合成，注意这里不使用dTTP，而是使用dUTP。</li><li>然后，先使用Klenow酶来给3’末端添加一个突出的A；再连接adapter，注意这里的adapter结构；</li><li>然后再进行PCR反应，由于DNA聚合酶不能以dUTP为模板，所以以sense strand为模板的链没有办法参与到PCR中，因此最终的双链DNA都是右下角那样的。<br>（需要先降解dUTP链？）<br>我们最终可以看到，Read1测到的是antisense strand的信息，Read2测到的是sense strand的信息，这和我们之前的理解是一样的哈。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;链特异性测序&lt;/p&gt;</summary>
    
    
    
    <category term="Genomics" scheme="http://blog.ligene.cn/categories/Genomics/"/>
    
    
    <category term="NGS" scheme="http://blog.ligene.cn/tags/NGS/"/>
    
  </entry>
  
  <entry>
    <title>贝叶斯定理与HIV检测</title>
    <link href="http://blog.ligene.cn/2022/06/04/bayes-hiv/"/>
    <id>http://blog.ligene.cn/2022/06/04/bayes-hiv/</id>
    <published>2022-06-04T12:33:26.000Z</published>
    <updated>2023-01-12T01:14:30.219Z</updated>
    
    <content type="html"><![CDATA[<p>很多疾病的检测结果通常是阴性(-)和阳性(+)两种情况，艾滋病(AIDS)也不例外。目前，HIV(艾滋病病毒)检测方式是做血清抗体检测。任何医学检测都不会100%准确，数据的统计结果显示，真正得了艾滋病的患者在接受HIV检测后,结果呈现阳性的概率为99.8%，而健康人群检测结果为阴性的概率为99%。总体来说，检测结果还是很可靠的，得病的人基本会被检测出来，没有得病的人也能被准确甄选出来。</p><span id="more"></span>  <p>老王是A国居民，A国人口总共有100万，A国的艾滋病感染率为0.0666%，这个概率属于艾滋病高发区。某天老王参加完聚会后感觉身体不舒服，于是去医院检查，检测结果是HIV阳性，老王非常害怕。那么老王实际得艾滋病的概率是多大呢？<br>我们将使用贝叶斯定理[1]的方法计算老王的得病概率。<br>$$P(A|B)&#x3D;\frac{P(B|A)P(A)}{P(B)}$$<br>贝叶斯公式具体解释就是：在B出现的前提下A出现的概率，等于以A为前提B出现的概率与A出现概率的乘积，再除以B出现的概率。换句话说，就是后验概率和先验概率的关系。</p><p>根据故事背景，要求的是老王在检测为阳性的情况下患病的概率，即P(患病|阳性)，<br>我们假设：</p><ul><li>A: 患者得这种病</li><li>B: 检验结果呈阳性</li></ul><p>已知条件如下：</p><ol><li>P(A)&#x3D;0.0666% – A国的艾滋病感染率为0.0666%。</li><li>P(B|A)&#x3D;0.998 –艾滋病患者在接受检测后的结果呈阳性的概率为99.8%。</li><li>P(B|A拔)&#x3D;0.01 –健康人群检测结果为阴性的概率为99%，则为阳性的概率为1%。</li><li>A国总人口为100万。<br>则P(A|B)是多少? 即检验结果呈阳性并传染上该病的概率是多少?</li></ol><p>根据贝叶斯定理，在血液检测阳性的的人群中，确定感染HIV的概率：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">P(患病|阳性) = P(阳性|患病) X P(患病) / ( P(阳性|患病) X P(患病) + P(阳性|未患病) X P(未患病) )</span><br><span class="line">            = 0.998 * 0.000666 / 0.998 * 0.000666 + 0.01 * (1-0.000666) = 0.062363</span><br></pre></td></tr></table></figure><p>在老王检测结果呈阳性的情况下，老王得艾滋病的概率仅为6.24%。</p><p>各类人群的人数总结如下表所示：</p><table><thead><tr><th>结果</th><th>患者</th><th>健康者</th><th>总计</th></tr></thead><tbody><tr><td>阳性</td><td>655</td><td>9993</td><td>10658</td></tr><tr><td>阴性</td><td>1</td><td>989341</td><td>989342</td></tr></tbody></table><p>即P(患病|阳性) &#x3D; 665&#x2F;10658 &#x3D; 6.24% 。</p><h3 id="为什么检测阳性而患病概率这么低？"><a href="#为什么检测阳性而患病概率这么低？" class="headerlink" title="为什么检测阳性而患病概率这么低？"></a>为什么检测阳性而患病概率这么低？</h3><p>这是因为虽然老王的检测结果呈阳性，但是假阳性的人数很多，因此即使老王的检测结果为阳性，也存在很大的概率并未得病。这也是艾滋病筛查需要检测多次的原因，通过多轮检测，层层筛选后，概率自然就会提高。</p><hr><p><img src="http://www.ligene.cn/images/bayes.jpg" alt="Bayes"><br>Thomas Bayes (1701-1761)，英国牧师、业余数学家、统计师。贝叶斯出身于牧师之家，其父Joshua Bayes是伦敦长老会牧师。1719年，18岁的贝叶斯继承家族传统，进入爱丁堡大学修读逻辑学和神学，毕业后顺理成章成为一位牧师。在牧师的工作之余，贝叶斯对数学和逻辑推断抱有强烈的兴趣，有传言说，贝叶斯希望通过统计概率，证明上帝的存在。然而，终其一生，他没有实现这个愿望。被冠以“Bayes”之名的贝叶斯定理，则是在贝叶斯过世之后，由另一位牧师Richard Price从他的笔记中整理发表的。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;很多疾病的检测结果通常是阴性(-)和阳性(+)两种情况，艾滋病(AIDS)也不例外。目前，HIV(艾滋病病毒)检测方式是做血清抗体检测。任何医学检测都不会100%准确，数据的统计结果显示，真正得了艾滋病的患者在接受HIV检测后,结果呈现阳性的概率为99.8%，而健康人群检测结果为阴性的概率为99%。总体来说，检测结果还是很可靠的，得病的人基本会被检测出来，没有得病的人也能被准确甄选出来。&lt;/p&gt;</summary>
    
    
    
    <category term="Statistics" scheme="http://blog.ligene.cn/categories/Statistics/"/>
    
    
    <category term="Bayes" scheme="http://blog.ligene.cn/tags/Bayes/"/>
    
  </entry>
  
  <entry>
    <title>BioEdit本地BLAST</title>
    <link href="http://blog.ligene.cn/2022/04/03/bioedit-blast/"/>
    <id>http://blog.ligene.cn/2022/04/03/bioedit-blast/</id>
    <published>2022-04-03T08:09:47.000Z</published>
    <updated>2023-01-15T16:24:06.261Z</updated>
    
    <content type="html"><![CDATA[<p>本练习使用BioEdit进行本地BLAST操作，鉴定16S rDNA测序序列的物种分类。</p><span id="more"></span><p>BLAST是“Basic Local Alignment Search Tool”的简称，顾名思义，它是基于局部比对算法的搜索工具，可将输入的查询序列(核酸或蛋白质)与数据库中的已知序列进行比对，获得与查询序列相似的已知序列，从而判断查询序列的来源或进化关系等。</p><p>一般可通过NCBI网站使用在线BLAST工具，但有时也需要进行本地BLAST，如实验室新测序了一个新细菌的基因组，还没有将此基因组上传的GenBank数据库，将无法通过NCBI在线BLAST搜索此新基因组中的基因。NCBI网站提供最新版本的本地BLAST软件(<a href="https://blast.ncbi.nlm.nih.gov)./">https://blast.ncbi.nlm.nih.gov)。</a></p><p>本练习使用bioedit软件实现BLAST搜索同源序列，鉴定一个16S测序序列的物种分类。BioEdit使用比较方便，整合了构建数据库和各种BLAST算法(如下图)，但BioEdit集成的BLAST软件是比较老的版本。<br><img src="http://www.ligene.cn/images/book/bioedit-1.png" alt="Local BLAST"></p><blockquote><p>注：可从配套百度网盘下载bioedit软件及相关文件:<br><a href="https://pan.baidu.com/s/1eMiHyb7mW4Nrbsfpw9JtdA">https://pan.baidu.com/s/1eMiHyb7mW4Nrbsfpw9JtdA</a> (提取码: txh5)。</p></blockquote><h3 id="下载并安装BioEdit"><a href="#下载并安装BioEdit" class="headerlink" title="下载并安装BioEdit"></a>下载并安装BioEdit</h3><p>安装BioEdit的默认路径为C:\BioEdit\，如要修改安装路径，软件可能会报错。</p><blockquote><p>可从配套百度网盘文件夹Resources目录下载bioedit软件。</p></blockquote><h3 id="准备查询序列与数据库"><a href="#准备查询序列与数据库" class="headerlink" title="准备查询序列与数据库"></a>准备查询序列与数据库</h3><p>可使用核酸或蛋白质序列，本练习使用：</p><ul><li>1)查询序列文件(16S_rRNA_sequences.txt): 两条测序得到的肠道微生物16S rDNA序列。</li><li>2)细菌16S序列数据库(16SMicrobial.tar.gz): 此数据库为从NCBI网站下载的已经构建好的BLAST数据库，解压后会看到8个文件。</li></ul><blockquote><p>注：两文件可从配套网盘文件夹ch05BLAST下载。数据库文件是压缩文件需要解压使用，可使用解压缩软件，如WINRAR、7-zip等。</p></blockquote><h3 id="准备本地序列数据库"><a href="#准备本地序列数据库" class="headerlink" title="准备本地序列数据库"></a>准备本地序列数据库</h3><p>如果要把基因组数据做成本地数据库，可通过: </p><ul><li>1)菜单create a local nucleotide database file建立本地DNA数据库</li><li>2)菜单create a local protein database file建立本地蛋白质数据库<br>用于建库的原始数据需要做成fasta格式。</li></ul><p> 本练习直接用NCBI网站提供的已经格式化的16S序列数据库，不需要从头建库：<br>  将前面解压后16SMicrobial目录下的8个文件复制到BioEdit安装目录下的database文件夹(c:\bioedit\database)即可。</p><ol start="4"><li>运行Local BLAST</li></ol><p>Local BLAST窗口的参数设置如图所示：<br><img src="http://www.ligene.cn/images/book/bioedit-2.png" alt="BLAST参数"></p><ul><li><p>由于本练习所用查询序列与数据库序列都是DNA序列，因此Program选blastn，数据库选择Nucleotide Database的16SMicrobial，注意要点击一下16SMicrobial下拉框并选择此数据库。如果为蛋白质序列则要相应选blastp与Protein Database。</p></li><li><p>将16SRNA sequences.txt中的DNA序列复制粘贴到Query输入框中。</p><blockquote><p>注意不要复制fasta格式中的注释行(&gt;开头)。</p></blockquote></li><li><p>另外，将E-value值设置为1e-6或更小的值，默认值1.0将找到许多不相似的序列，e-value值越小，能找到的序列越相似。但e-value设置为一个很小的值可能找不相序的序列(no hits)，可根据需要调整e-value。其它参数可不用设置。</p></li><li><p>最后点击Do Search进行分析。</p></li></ul><h3 id="解读BLAST结果"><a href="#解读BLAST结果" class="headerlink" title="解读BLAST结果"></a>解读BLAST结果</h3><p>BLAST结果如下图所示：<br><img src="http://www.ligene.cn/images/book/bioedit-3.png" alt="BLAST结果"></p><p>结果部分前面有参考文献、碱基长度等信息，下面是获得的同源序列，显示数据库对应序列的ID及注释信息，并根据比对分数(Score)由高到低排列。上图所示的比对匹配分数最高的序列是源自艰难梭菌菌株(clostridium difficile)，即此菌分类可鉴定为艰难梭菌。</p><blockquote><p>注意，16S序列比对可能与不同物种的比对具有相同的分数，因此无法确定哪个菌株最合适，说明只靠16S序列信息有时是不能注释到种(species)水平。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;本练习使用BioEdit进行本地BLAST操作，鉴定16S rDNA测序序列的物种分类。&lt;/p&gt;</summary>
    
    
    
    <category term="Bioinformatics" scheme="http://blog.ligene.cn/categories/Bioinformatics/"/>
    
    
    <category term="BLAST" scheme="http://blog.ligene.cn/tags/BLAST/"/>
    
    <category term="Tools" scheme="http://blog.ligene.cn/tags/Tools/"/>
    
  </entry>
  
  <entry>
    <title>基于DADA2的16S rRNA扩增子测序数据分析流程</title>
    <link href="http://blog.ligene.cn/2022/03/16/win16s-DADA2/"/>
    <id>http://blog.ligene.cn/2022/03/16/win16s-DADA2/</id>
    <published>2022-03-15T21:57:09.000Z</published>
    <updated>2023-01-12T01:20:14.511Z</updated>
    
    <content type="html"><![CDATA[<p>本16S rRNA基因扩增子测序数据分析流程包括：首先通过R语言中DADA2包对样本测序数据进行质控与预处理；然后得到样本的ASV表与物种分类信息；最后通过MicrobiomeAnalyst可视化样本数据，查看样品中的细菌种类，并进行生物多样性(biodiversity)统计分析。</p><span id="more"></span><h2 id="1-DADA2"><a href="#1-DADA2" class="headerlink" title="1. DADA2"></a>1. DADA2</h2><p>本流程所有命令都要在R环境中运行，请先安装R软件。</p><h3 id="1-1-相关软件与数据"><a href="#1-1-相关软件与数据" class="headerlink" title="1.1 相关软件与数据"></a>1.1 相关软件与数据</h3><p>(1)安装DADA2（当前版本1.16）的二进制文件可从Bioconductor获得。注意，你必须拥有R3.6.1或更新版本，以及Bioconductor版本3.10。为防止安装R包时遇到Windows文件夹不能写入问题，需以管理员权限运行R软件进行安装。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE))</span><br><span class="line">    install.packages(&quot;BiocManager&quot;)</span><br><span class="line">BiocManager::install(&quot;dada2&quot;, version = &quot;3.10&quot;)</span><br><span class="line">library(dada2) </span><br></pre></td></tr></table></figure><p>(2)从网址(<a href="https://benjjneb.github.io/dada2/training.html)%E4%B8%8B%E8%BD%BDSilva%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%8B%E7%BC%A9%E5%8C%85silva_nr_v138_train_set.fa.gz%E5%92%8Csilva_species_assignment_v138.fa.gz%E3%80%82">https://benjjneb.github.io/dada2/training.html)下载Silva数据库压缩包silva_nr_v138_train_set.fa.gz和silva_species_assignment_v138.fa.gz。</a></p><p>(3)16S测序原始数据(raw reads)<br>本实验需要把所有Illumina测序原始数据放在一个文件夹（如D:\win16s\raw_reads）。一个样品的双端测序有两个reads文件，默认以”_R1.fastq”与”_R2.fastq”分别代表正向与反向测序reads （如果文件名不对，需要重新命名）。测序公司提供的样本测序数据一般已去除barcode和primer序列。</p><h3 id="1-2-分析过程"><a href="#1-2-分析过程" class="headerlink" title="1.2 分析过程"></a>1.2 分析过程</h3><p>（1）数据获取</p><ul><li><p>设置工作路径，此路径内有多个样本的两端测序数据的压缩文件，如SAA_R1.fastq.gz, SAA_R2.fastq.gz等。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">path&lt;-&quot;D:/win16s/&quot;</span><br><span class="line">list.files(path)</span><br><span class="line">fnFs &lt;- sort(list.files(path, pattern=&quot;.R1.fastq&quot;, full.names = TRUE))</span><br><span class="line">fnRs &lt;- sort(list.files(path, pattern=&quot;.R2.fastq&quot;, full.names = TRUE))</span><br></pre></td></tr></table></figure></li><li><p>获取样本文件名（无后缀）</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sample.names &lt;- sapply(strsplit(basename(fnFs), &quot;_&quot;), `[`, 1)  # </span><br></pre></td></tr></table></figure></li><li><p>数据质量检测（正反向两个Reads）,可以看到Read末端的质量较差</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">plotQualityProfile(fnFs[1:2])</span><br><span class="line">plotQualityProfile(fnRs[1:2])</span><br></pre></td></tr></table></figure><p>（2）数据过滤和裁剪</p></li><li><p>指定过滤后的文件名<br>filtFs &lt;- file.path(path, “filtered”, paste0(sample.names, “_F_filt.fastq.gz”))<br>filtRs &lt;- file.path(path, “filtered”, paste0(sample.names, “_R_filt.fastq.gz”))<br>names(filtFs) &lt;- sample.names<br>names(filtRs) &lt;- sample.names<br>out &lt;- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen&#x3D;c(220, 220), maxN&#x3D;0, maxEE &#x3D; c(2,2),  truncQ&#x3D;2, rm.phix&#x3D;TRUE,   compress&#x3D;TRUE)<br>head(out)</p></li><li><p>filterAndTrim里参数详情可参考R帮助文件<br>truncQ: truncate读取质量分数小于或等于truncQ的第一个实例。<br>truncLen: truncLen base后的Truncate读段，小于此值的读取将被丢弃。<br>maxEE: 在裁剪后，将丢弃大于maxEE“预期错误”的读段。预期误差由质量分数的名义定义计算:EE &#x3D; sum(10^(-Q&#x2F;10))</p></li></ul><p>(3)学习错误率(Learn the Error Rates)</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">errF &lt;- learnErrors(filtFs, multithread=TRUE)</span><br><span class="line">errR &lt;- learnErrors(filtRs, multithread=TRUE)</span><br></pre></td></tr></table></figure><ul><li>基于错误率模型进一步质控<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dadaFs &lt;- dada(filtFs, err=errF, multithread=TRUE)</span><br><span class="line">dadaRs &lt;- dada(filtRs, err=errR, multithread=TRUE)</span><br><span class="line">dadaFs[[1]]</span><br></pre></td></tr></table></figure></li></ul><p>（4）序列拼接<br>将正向与反向序列合并成一个完整的序列</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mergers &lt;- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE, minOverlap = 0) # 参数minOverlap值？</span><br><span class="line">#mergers &lt;- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE, justConcatenate=TRUE) #justConcatenate=TRUE在两个序列间直接插入10个N拼接</span><br></pre></td></tr></table></figure><p>(5）生成ASV表</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqtab &lt;- makeSequenceTable(mergers)</span><br><span class="line">dim(seqtab)</span><br></pre></td></tr></table></figure><ul><li>查看序列长度分布<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">table(nchar(getSequences(seqtab)))</span><br></pre></td></tr></table></figure></li></ul><p>（6）去除嵌合体</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqtab.nochim &lt;- removeBimeraDenovo(seqtab, method=&quot;consensus&quot;, multithread=TRUE, verbose=TRUE)</span><br><span class="line">dim(seqtab.nochim)</span><br><span class="line">sum(seqtab.nochim)/sum(seqtab)</span><br><span class="line"># 求和函数，计算分析过程中的reads数量</span><br><span class="line">getN &lt;- function(x) sum(getUniques(x))</span><br><span class="line"># 合并各样本分步数据量，如果只处理一个样本，将sapply(dadaFs, getN) 代替为 getN(dadaFs)</span><br><span class="line">track &lt;- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))</span><br><span class="line">colnames(track) &lt;- c(&quot;input&quot;, &quot;filtered&quot;, &quot;denoisedF&quot;, &quot;denoisedR&quot;, &quot;merged&quot;, &quot;nonchim&quot;)</span><br><span class="line">rownames(track) &lt;- sample.names  #行名修改为样本名</span><br><span class="line"># 统计结果预览</span><br><span class="line">head(track)</span><br></pre></td></tr></table></figure><p>（7）物种注释</p><ul><li>序列物种注释<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">taxa &lt;- assignTaxonomy(seqtab.nochim, paste0(path, &quot;/silva_nr_v138_train_set.fa.gz&quot;), multithread=TRUE,tryRC = TRUE)</span><br><span class="line">#taxa &lt;- addSpecies(taxa, paste0(path, &quot;/silva_species_assignment_v138.fa.gz&quot;))</span><br><span class="line">taxa.print &lt;- taxa </span><br><span class="line">rownames(taxa.print) &lt;- NULL</span><br><span class="line">head(taxa.print)</span><br></pre></td></tr></table></figure></li></ul><p>（8）分析文件保存<br>taxa.print &lt;- as.data.frame(taxa.print)<br>taxa.name &lt;- paste (taxa.print$Kingdom, taxa.print$Phylum, taxa.print$Class, taxa.print$Order, taxa.print$Family, taxa.print$Genus, sep&#x3D;”;”)<br>seqtable.taxa &lt;- cbind(‘#NAME’&#x3D; taxa.name, t(seqtab.nochim))<br>rownames(seqtable.taxa) &lt;- NULL<br>head(seqtable.taxa)</p><ul><li><p>带注释文件的ASV表格导出<br>setwd(path)<br>write.csv(seqtable.taxa , “dada2_counts.taxa.csv”, quote&#x3D;F, row.names&#x3D;F)</p></li><li><p>ASV表格导出<br>write.table(t(seqtab.nochim), “dada2_counts.asv.txt”, sep&#x3D;”\t”, quote&#x3D;F, row.names &#x3D; T)</p></li></ul><p>（8）统计相同菌种的总和<br>利用EXCEL软件合并重复项的SUMIF方法(<a href="https://www.kafan.cn/A/pvw72jpyn7.html)%E5%AF%B9%E4%B8%8A%E9%9D%A2%E5%BE%97%E5%88%B0%E7%9A%84%E6%96%87%E4%BB%B6(dada2_counts.taxa.csv)%E4%B8%AD%E7%9A%84%E7%9B%B8%E5%90%8C%E8%8F%8C%E5%B1%9E%E8%BF%9B%E8%A1%8C%E6%B1%87%E6%80%BB%EF%BC%8C%E5%B0%86%E5%BE%97%E5%88%B0%E6%9C%80%E5%90%8E%E7%9A%84%E7%BB%93%E6%9E%9C%E5%A4%8D%E5%88%B6%E7%B2%98%E8%B4%B4%EF%BC%88%E9%BC%A0%E6%A0%87%E5%8F%B3%E9%94%AE%E8%8F%9C%E5%8D%95%E9%80%89%E6%8B%A9%E7%B2%98%E8%B4%B4%E9%80%89%E9%A1%B9%E4%B8%BA%E5%80%BC%EF%BC%89%E5%88%B0dada2_new.taxa.csv">https://www.kafan.cn/A/pvw72jpyn7.html)对上面得到的文件(dada2_counts.taxa.csv)中的相同菌属进行汇总，将得到最后的结果复制粘贴（鼠标右键菜单选择粘贴选项为值）到dada2_new.taxa.csv</a>(格式见下图）,并可根据实际情况对其样本名进行修改（注意上方的#NAME），用于后续的生物信息学分析。</p><p>注：SUMIF($A$2:$A$1642,$M2,B$2:B$1642)</p><h2 id="2-MicrobiomeAnalyst"><a href="#2-MicrobiomeAnalyst" class="headerlink" title="2. MicrobiomeAnalyst"></a>2. MicrobiomeAnalyst</h2><p>2.1数据分析<br>准备两个文件dada2_new.species.csv和metedata.csv（metedata.csv格式如下，注意上方的#NAME），用这两个表在microbiomeanalyst网站即可进行多样性数据分析。</p><p>1）打开microbiomeanalyst网站(<a href="https://www.microbiomeanalyst.ca/),%E9%80%89%E6%8B%A9MDP">https://www.microbiomeanalyst.ca/),选择MDP</a></p><p>2）将dada2_new.species.csv和metedata.csv载入（勾选Taxonomy labels included），选择分类数据库，这里我们选择SILVA Taxonomy.</p><p>3）这里展示一些数据基本信息，查看数据间匹配程度，接着下一步</p><p>4） 进行数据过滤<br>数据过滤的目的是去除低质量或无信息的特征，以改善下游的统计分析。你可以通过拖动滑块到左端(值:0)来禁用任何数据过滤器。低计数过滤器（Low count filter)——在很少的样本中具有非常小的计数的特性可能是由于排序错误或低水平污染造成的。首先需要指定一个最小计数(默认为4)。20%流行度过滤器意味着至少20%的值应该包含至少4个计数。您还可以根据它们的平均值或中值进行过滤。低方差滤波器(Low variance filter)——在整个实验条件中接近常数的特征不太可能与所研究的条件相关联。它们的方差可用分位数间量程(IQR)、标准差或变异系数(CV)来测量。默认情况下，所有下游数据分析都将基于过滤后的数据。你可以选择使用原始的未经过滤的数据进行一些分析(例如alpha多样性)。</p><ol start="5"><li>标准化<br>归一化的目的是解决采样深度的可变性和数据的稀疏性，以实现更具生物学意义的比较。当库的大小非常不同时(i.e. &gt; 10 times)，稀薄化也被推荐。注:rarefying主要用于16S marker基因数据，不能用于shotgun元基因组数据。所有这些方法都需要原始计数数据作为输入。可以通过数据伸缩或数据转换来简化数据。但是，您不能同时应用数据伸缩和数据转换，因为伸缩或转换的数据不再是有效的计数数据。<br>数据伸缩：<br>TSS：总和比例<br>CSS: 累积比例<br>UQ: 上四分位数标准化<br>数据转换：好像是一些对数转换，感觉可以理解为类似于将1转换为log1010<br>在统计学当中由于要对多指标进行综合分析，而指标的核心就是均值和标准差，那如果想要将均值和标准差结合起来一起分析，那就需要进行数据的标准化处理，从而消除变量分布不同的影响，然后在综合分析的时候才具有统计意义。<br>RLE：相对对数表达量<br>TMM:<br>CLR:集中对数比率</li></ol><p>5） 接下来就到了可视化分析结果，主要展现四部分。<br>A. 柱状图<br>1.General options:<br>Taxonomy level :选择分类水平（ phylum class order family genus）<br>Graph type:选择图形类型（stacked bar(actual abundance)；stacked bar(percentage abundance)；stacked area plot）<br>2. Taxa resolution<br>Merging small taxa with counts：少于指定的截止计数的特性将被丢弃到“其他”中<br>Showing top n taxa：只展示计数多的前n个<br>3. View options<br>Organize samples by：是否按分组展示</p><p>B. 稀释曲线<br>稀释性曲线可以用来比较测序不同的样本中物种的丰富度，也可以用来说明样本的测序数据量是否足够，是否需要加测数据。对某个样本来说，当曲线趋末端向平坦时，说明测序数据量合理，更多的数据量只会产生少量新的OTU，反之则说明测序深度不足以覆盖大多数菌，继续测序还可能产生较多新的OTU。因此，通过作稀释性曲线，可得出样品的测序深度情况。对于不同的样本（也就是不同颜色的曲线）来说，位于上方的样本物种的丰富度要高于位于下方的样本。<br>主要是一些展现分组的选择<br>Data source :选择原始或过滤的数据<br>Setps：分布绘制曲线，改变曲线的圆滑性</p><p>C. alpha多样性<br>alpha多样性是用来衡量个体内菌群的一个多样性如何，注意是单个个体，不涉及个体间的比较<br>Diversity measure：多样性度量<br>Observed：考虑物种丰富度<br>chao1:chao1是度量物种丰富度的指标，它和丰度、均匀度无关，但是它对稀有的物种很敏感。<br>ACE:ACE指数在生态学中同样作为度量物种丰富度的指标,其值越高代表群落物种越丰富<br>Shannon:同时考虑了物种丰富度以及均匀度<br>Simpson:辛普森指数（Simpson index）同样考虑了物种丰富度以及均匀度，但与Shannon指数相比，它更受均匀度的影响<br>Fisher:同时考虑了物种丰富度以及均匀度<br>Statistical method:统计方法<br>T-test&#x2F;ANOVA：独立样本baiT检验一般仅仅比较两组数据du有没有区别，区别的显著性，如比较zhi两组人的身高，体重等dao等，而这两组一般都是独立的，没有联系的，只是比较这两组数据有没有统计学上的区别或差异。单因素ANOVA也就是单因素方差分析，是用来研究一个控制变量的不同水平是否对观测变量产生了显著影响。说白了就是分析x的变化对y的影响的显著性，所以一般变量之间存在某种影响关系的，验证一种变量的变化对另一种变量的影响显著性的检验。一般的，方差分析都是配对的。<br>Mann-Whitney&#x2F;Kruskal-Wallis： Mann-Whitney检验假设两个样本分别来自除了总体均值以外完全相同的两个总体，目的是检验这两个总体的均值是否有显著的差别。Kruskal-Wallis检验用于多个连续型独立bai样本的比较。方du差分析程序关注的是，几个总体的均值zhi是否相等。数据是间隔测量尺度或比率测量尺度的数据。</p><p>D. beta多样性<br>beta多样性的计算是为了表征个体间微生物组成相似性的一个指标，个体之间物种的有无和不一致性通常影响beta多样性指数，当然alpha多样性指数也会影响beta多样性指数。<br>Ordination method :<br>PCoA：主坐标轴分析<br>NMDS：非度量多维尺度法是一种将多维空间的研究对象（样本或变量）简化到低维空间进行定位、分析和归类，同时又保留对象间原始关系的数据分析方法。<br>Distance method:数学中不同距离计算方法<br>Bray-Curtis Index<br>Jensen-Shannon Divergence<br>Jaccard Index<br>Unweighted UniFrac Distance<br>weighted UniFrac Distance<br>Statisitical method:统计方法<br>Permutational MANOVA:置换多因素方差分析<br>Analysis of Group Similarities:检验样品组间的差异显著性<br>Homogeneity of Group Dispersions:群分散的同质性</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本16S rRNA基因扩增子测序数据分析流程包括：首先通过R语言中DADA2包对样本测序数据进行质控与预处理；然后得到样本的ASV表与物种分类信息；最后通过MicrobiomeAnalyst可视化样本数据，查看样品中的细菌种类，并进行生物多样性(biodiversity)统计分析。&lt;/p&gt;</summary>
    
    
    
    <category term="Genomics" scheme="http://blog.ligene.cn/categories/Genomics/"/>
    
    
    <category term="16S" scheme="http://blog.ligene.cn/tags/16S/"/>
    
  </entry>
  
  <entry>
    <title>scikit learn</title>
    <link href="http://blog.ligene.cn/2022/03/16/scikit-learn/"/>
    <id>http://blog.ligene.cn/2022/03/16/scikit-learn/</id>
    <published>2022-03-15T21:51:29.000Z</published>
    <updated>2023-01-12T01:19:36.127Z</updated>
    
    <content type="html"><![CDATA[<p>scikit-learn(简称sklearn)是基于Python语言的第三方机器学习库。scikit-learn是一个开源项目，包含目前几乎所有主流机器学习算法，其官方文档对每个算法都有详细的说明与示例，完全可以当成机器学习的教程来学习。scikit-learn的主要功能包括分类、回归、聚类、数据降维、模型选择和数据预处理六大部分。</p><span id="more"></span><h2 id="安装scikit-learn"><a href="#安装scikit-learn" class="headerlink" title="安装scikit-learn"></a>安装scikit-learn</h2><p>在安装scikit-learn之前，系统需要已经安装了Python语言的基本运行环境可。<br>使用Python的包管理工具pip进行安装：<br><code>pip install scikit-learn</code><br>安装完成后，在Python编译环境下运行以下代码检验安装是否成功：<br><code>import sklearn</code><br>如果成功导入scikit-learn库，没有报错，表明scikit-learn安装成功。</p><h2 id="应用实例"><a href="#应用实例" class="headerlink" title="应用实例"></a>应用实例</h2><p>对于具体的机器学习问题，通常可以分为三个步骤：</p><ul><li>数据准备与预处理</li><li>模型选择与训练</li><li>模型验证与参数调优</li></ul><p>下面通过简单的鸢尾花实例介绍机器学习开发的一般流程，包含从数据导入到模型选择，以及对模型进行训练和预测的整个过程。</p><h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><p>鸢尾花(Iris)数据集可以在scikit-learn的sklearn.datasets模块中找到，并使用模块的load_iris方法加载。鸢尾花数据集描述了三个不同的鸢尾花种类（setosa, versicolor, virginicsa），共有150个样本，每个样本有4个特征，分别为花萼(sepal)的长度与宽度，花瓣(petal)的长度与宽度。为了数据处理方便，该数据集将三个不同种类的花分别用0、1、2表示。<br>scikit-learn中的数据通常用大写的X表示，而标签用小写的y表示。scikit-learn中的train_text_split方法利用伪随机数生成器可以将数据集分为训练集和测试集并将数据随机打乱。train_text_split方法的输出为X_train、X_test、y_train和y_test，其中X_train包含75%的数据，X_test包含另外25%的数据。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import sklearn</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">iris_dataset = load_iris()</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(iris_dataset[&#x27;data&#x27;], iris_dataset[&#x27;target&#x27;], random_state=0)</span><br><span class="line">print(&quot;X_train shape:&quot;, X_train.shape)</span><br><span class="line">print(&quot;y_train shape:&quot;, y_train.shape)</span><br></pre></td></tr></table></figure><p>输出结果：<br>X_train shape:(112, 4)<br>y_train shape:(112,)</p><p>在构建机器学习模型之前，首先应检查数据，以确定数据集的特征属性是否完整。检查数据的最佳方法之一就是将其可视化。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">iris_dataframe = pd.DataFrame(X_train, columns= iris_dataset.feature_names)</span><br><span class="line">pd.DataFrame.hist(iris_dataframe, figsize=(6, 6))</span><br><span class="line">pd.plotting.scatter_matrix(iris_dataframe, figsize=(16, 12))</span><br></pre></td></tr></table></figure><h3 id="选择和训练模型"><a href="#选择和训练模型" class="headerlink" title="选择和训练模型"></a>选择和训练模型</h3><p>不同的机器学习模型针对某一特定问题有不同的执行效率和准确度，因此针对特定问题选择合适的模型非常重要。这里选择使用K近邻分类算法。<br>机器学习模型的构建主要分两大部分：模型训练和模型测试。模型训练是在数据集上训练机器学习模型的参数及拓扑结构，模型测试是对已训练模型的精度、准确度等进行测试。通常将数据集分为训练数据集与测试数据集两部分。训练数据集用来训练模型，模型训练好后，在测试集上测试模型的性能，以判断模型的泛化能力(generalization ability)。泛化能力的强弱是选择机器学习模型的重要依据。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=1)</span><br><span class="line">knn.fit(X_train, y_train)</span><br></pre></td></tr></table></figure><p>n_neighbors是knn中最重要的参数，可以通过交叉验证来设置一个合理的值。<br>接着使用fit方法在训练数据上进行拟合，kNN是一个有监督的学习算法，因此在拟合数据的时候，需要将已知的类别标签train_y与特征train_X一起输入到模型中进行数据拟合。</p><h3 id="使用模型"><a href="#使用模型" class="headerlink" title="使用模型"></a>使用模型</h3><p>对模型进行训练后，需要使用新数据对模型的性能进行预测。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">X_new = np.array([[5,2.6,1,0.2]])</span><br><span class="line">print(&quot;X_new.shape:&quot;, X_new.shape)</span><br></pre></td></tr></table></figure><p>输出结果：<br>X_new.shape:(1, 4)</p><p>确定数据符合预期要求后，调用模型的predict方法对数据样本进行预测：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pred = knn.predict(X_new)</span><br><span class="line">print(&quot;Prediction:&quot;, pred)</span><br><span class="line">print(&quot;Predicted target name:&quot;, iris_dataset[&#x27;target_names&#x27;][pred])</span><br></pre></td></tr></table></figure><p>输出结果：<br>Prediction:[0]<br>Predicted target name:[‘setosa’]<br>经过模型预测，此鸢尾花的品种属于setosa。</p><h3 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h3><p>使用训练好的模型，对测试集进行预测，预测结果与测试集的数据标签进行比较，通过计算准确率（鸢尾花品种预测正确所占的比例）来衡量模型的好坏。为了更好地评估模型在新数据集上的错误率，一般使用更复杂的方法-交叉验证(cross validation)。评估模型可以确定模型在数据集上的泛化能力，而模型优化可以提升模型的泛化能力。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">y_pred = knn.predict(X_test)</span><br><span class="line">print(&quot;Test set predictions:\n&quot;, y_pred)</span><br><span class="line">print(&quot;Test set score: &#123;:.2f&#125;&quot;.format(np.mean(y_pred == y_test)))</span><br></pre></td></tr></table></figure><p>输出结果：<br>Test set score: 0.97<br>所得结果显示模型的精度为0.97，即正确率为97%。</p><h3 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h3><p>模型本身就是一个Python的对象，可以使用pickle的方式将模型转储到文件，但sklearn推荐使用其joblib接口，保存与加载模型都非常简单：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import joblib</span><br><span class="line">joblib.dump(knn, &#x27;/tmp/model.pkl&#x27;)        #保存模型</span><br><span class="line">model = joblib.load(&#x27;/tmp/model.pkl&#x27;)       #加载模型</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;scikit-learn(简称sklearn)是基于Python语言的第三方机器学习库。scikit-learn是一个开源项目，包含目前几乎所有主流机器学习算法，其官方文档对每个算法都有详细的说明与示例，完全可以当成机器学习的教程来学习。scikit-learn的主要功能包括分类、回归、聚类、数据降维、模型选择和数据预处理六大部分。&lt;/p&gt;</summary>
    
    
    
    <category term="Programming" scheme="http://blog.ligene.cn/categories/Programming/"/>
    
    
    <category term="AI" scheme="http://blog.ligene.cn/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu 20.04 LTS 更换阿里云源</title>
    <link href="http://blog.ligene.cn/2022/03/16/WSL-install/"/>
    <id>http://blog.ligene.cn/2022/03/16/WSL-install/</id>
    <published>2022-03-15T21:45:02.000Z</published>
    <updated>2023-01-12T01:20:30.414Z</updated>
    
    <content type="html"><![CDATA[<p>Ubuntu 20.04 LTS 更换阿里云源</p><ol><li><p>先备份原始源文件：<br><code>sudo cp /etc/apt/source.list /etc/apt/source.list.backup</code></p></li><li><p>修改文件:<br><code>vim  /etc/apt/source.list</code></p></li><li><p>清除原有的内容，替换为aliyun源:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">deb http://mirrors.aliyun.com/ubuntu/ focal main restricted</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ focal universe</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ focal-updates universe</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ focal multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ focal-updates multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ focal-security universe</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ focal-security multiverse</span><br></pre></td></tr></table></figure></li><li><p>保存，并执行更新：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo  apt update</span><br><span class="line">sudo  apt upgrade</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Ubuntu 20.04 LTS 更换阿里云源&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;先备份原始源文件：&lt;br&gt;&lt;code&gt;sudo cp /etc/apt/source.list /etc/apt/source.list.backup&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;</summary>
      
    
    
    
    <category term="Tutorials" scheme="http://blog.ligene.cn/categories/Tutorials/"/>
    
    
    <category term="WSL" scheme="http://blog.ligene.cn/tags/WSL/"/>
    
  </entry>
  
  <entry>
    <title>eBook - Genomics and Personalized Medicine</title>
    <link href="http://blog.ligene.cn/2022/03/06/Precision-Medicine-Book/"/>
    <id>http://blog.ligene.cn/2022/03/06/Precision-Medicine-Book/</id>
    <published>2022-03-06T09:22:02.000Z</published>
    <updated>2023-01-12T01:18:47.798Z</updated>
    
    <content type="html"><![CDATA[<p>Genomics and Personalized Medicine: What Everyone needs to Know<br>此书为斯坦福大学Michael Snyder教授写的科普读物。</p><span id="more"></span><p>我一直以此书为《基因组学与精准医疗》课程的推荐教材，但国内没有出版英文书，以前也没有找到电子书。<br>今天用Bing搜索此书，终于在一家伊朗的生物信息学网站找到电子书：<br><a href="https://www.codecool.ir/extra/20203131236253What_Everyone_Needs_to_Know_Michael.pdf">https://www.codecool.ir/extra/20203131236253What_Everyone_Needs_to_Know_Michael.pdf</a></p><p>有需要的同学可以从以上<a href="https://www.codecool.ir/extra/20203131236253What_Everyone_Needs_to_Know_Michael.pdf">链接</a>或此国内<a href="http://www.ligene.cn/images/bigbook/What_Everyone_Needs_to_Know_Michael.pdf">链接</a>下载。</p><p>PS：也是第一次看到伊朗的科研网站<a href="https://www.codecool.ir/">codecool.ir</a>，特意看了一下，站如其名，比较cool👍</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Genomics and Personalized Medicine: What Everyone needs to Know&lt;br&gt;此书为斯坦福大学Michael Snyder教授写的科普读物。&lt;/p&gt;</summary>
    
    
    
    <category term="Genomics" scheme="http://blog.ligene.cn/categories/Genomics/"/>
    
    
    <category term="Teaching" scheme="http://blog.ligene.cn/tags/Teaching/"/>
    
  </entry>
  
  <entry>
    <title>博客同步到简书</title>
    <link href="http://blog.ligene.cn/2022/02/21/JianShu/"/>
    <id>http://blog.ligene.cn/2022/02/21/JianShu/</id>
    <published>2022-02-21T14:57:32.000Z</published>
    <updated>2023-01-12T01:16:01.696Z</updated>
    
    <content type="html"><![CDATA[<p>由于在简书平台写作比较方便，以后本博客将与简书平台同步。<br>简书专题：生物信息学与基因组学<br>链接: <a href="https://www.jianshu.com/c/974827f7bd5f">https://www.jianshu.com/c/974827f7bd5f</a><br>但简书的审查机制比较严，有些文章可能发不出来，还是要发在自建的博客平台。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;由于在简书平台写作比较方便，以后本博客将与简书平台同步。&lt;br&gt;简书专题：生物信息学与基因组学&lt;br&gt;链接: &lt;a href=&quot;https://www.jianshu.com/c/974827f7bd5f&quot;&gt;https://www.jianshu.com/c/974827f</summary>
      
    
    
    
    <category term="Tutorials" scheme="http://blog.ligene.cn/categories/Tutorials/"/>
    
    
  </entry>
  
  <entry>
    <title>SMS-生物序列分析的在线工具</title>
    <link href="http://blog.ligene.cn/2021/08/05/SMS/"/>
    <id>http://blog.ligene.cn/2021/08/05/SMS/</id>
    <published>2021-08-05T09:42:27.000Z</published>
    <updated>2023-01-12T01:19:56.450Z</updated>
    
    <content type="html"><![CDATA[<p>SMS (Sequence Manipulation Suite)是一个生物序列分析工具的集合。</p><span id="more"></span><p>SMS由JavaScript编写，使用十分方便，只要浏览器打开SMS网站(<a href="http://www.bioinformatics.org/sms2/index.html)%EF%BC%8C%E5%B0%B1%E5%8F%AF%E4%BB%A5%E7%9B%B4%E6%8E%A5%E8%BF%90%E8%A1%8C%E8%BF%99%E4%BA%9B%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E3%80%82%E4%BD%86%E5%9C%A8%E7%BA%BF%E4%BD%BF%E7%94%A8%E5%8F%AF%E8%83%BD%E5%8F%97%E7%94%B5%E8%84%91%E7%BD%91%E7%BB%9C%E9%80%9F%E5%BA%A6%E7%9A%84%E5%BD%B1%E5%93%8D%E4%BC%9A%E6%AF%94%E8%BE%83%E6%85%A2%EF%BC%8C%E4%BD%A0%E4%B9%9F%E5%8F%AF%E4%BB%A5%E5%85%8D%E8%B4%B9%E4%B8%8B%E8%BD%BD%E5%88%B0%E6%9C%AC%E5%9C%B0%E7%94%B5%E8%84%91%E4%B8%8A%EF%BC%8C%E8%A7%A3%E5%8E%8B%E5%90%8E%E7%A6%BB%E7%BA%BF%E4%BD%BF%E7%94%A8SMS%E3%80%82">http://www.bioinformatics.org/sms2/index.html)，就可以直接运行这些分析工具。但在线使用可能受电脑网络速度的影响会比较慢，你也可以免费下载到本地电脑上，解压后离线使用SMS。</a></p><blockquote><p>The Sequence Manipulation Suite is a collection of JavaScript programs for generating, formatting, and analyzing short DNA and protein sequences. It is commonly used by molecular biologists, for teaching, and for program and algorithm testing.</p></blockquote><p>SMS提供60多种常用的序列分析功能，主要包括格式转换（Format Conversion）、序列分析（Sequence Analysis）、序列作图（Sequence Figures）、随机序列（Random Sequences）和其他序列分析（Miscellaneous）5个部分。这些分析工具全部列在SMS网站主页的左边栏(见图1左侧)。<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/SMS_fig1.jpg" alt="SMS-HomePage"><br>图1. SMS网站主页</p><p>SMS网站提供很多DNA和蛋白质序列分析工具，如DNA&#x2F;蛋白质序列过滤，序列反向互补，蛋白质翻译和PCR引物分析等。下面就给大家简单介绍几个例子。</p><ol><li>GenBank文件特征提取<br>有时候我们得到了一个GenBank文件，想要拿到里面的mRNA，或者CDS序列。我们需要去看GenBank注释信息，然后找到对应mRNA的起始位点和终止位点，然后复制相应的序列，比较麻烦。SMS有一个GenBank Feature Extractor提取工具，可以很容易完成这件事情。<br>首先我们点击网站左边的“GenBank Feature Extractor”，弹出如图2页面，我们只需要将GenBank文件的内容粘贴到文本框里，点击提交按钮（submit）就可以。<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/SMS_fig2.jpg" alt="SMS-GenBank"><br>图 2. GenBank Feature Extractor分析页面</li></ol><p>SMS网站提供了一个示例，我们可以直接点击提交按钮，在新跳出的网页查看结果（见图3），拉下网页将看到生成了mRNA，CDS序列等，序列格式都是fasta。<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/SMS_fig3.jpg" alt="SMS-GenBank-Feature"><br>图 3. GenBank Feature Extractor结果页面</p><ol start="2"><li><p>反向互补序列<br>很多时候，如设计反向引物序列时，我们需要得到DNA序列的反向互补序列。SMS提供了序列反向互补处理功能。<br>点击网页左侧的“Reverse Complement”，出现如图4的页面，只要把我们的序列粘贴到文本框中，点击提交即可在新的页面看到结果，是不是so easy！该网页分别提供了参数选择框，可选择Reverse(反向)，或Complement（互补）序列分析。<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/SMS_fig4.jpg" alt="SMS-RevComp"><br>图 4. Reverse Complement分析页面</p></li><li><p>序列比对的保守序列分析<br>通过多序列比对找出保守序列是常见的生物信息分析之一。SMS网站提供了该项分析，并且可以将保守序列着色，突出显示。<br>点击网页左侧的“Color Align Conservation”，在弹出的页面的输入框中提供已经比对好的序列，还可以设置其他参数，如一致性或者相似性多少（Percentage of sequences that must agree for identity or similarity coloring to be added），着色背景还是文字（Used colored）等。<br>我们提交示例，使用默认参数，将看到下图结果，左边显示序列的名称，右边显示序列的位置。<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/SMS_fig5.jpg" alt="SMS-Align-Conservation"><br>图5. Color Align Conservation结果页面</p></li></ol><p>这种图在很多论文中都采用！如果想制作彩色比对，而不是黑白比对，可以试试另一个工具(Coloar Align Properties)，使用方法和Color Align Conservation工具一致。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;SMS (Sequence Manipulation Suite)是一个生物序列分析工具的集合。&lt;/p&gt;</summary>
    
    
    
    <category term="Bioinformatics" scheme="http://blog.ligene.cn/categories/Bioinformatics/"/>
    
    
  </entry>
  
  <entry>
    <title>findNum</title>
    <link href="http://blog.ligene.cn/2021/02/25/findNum/"/>
    <id>http://blog.ligene.cn/2021/02/25/findNum/</id>
    <published>2021-02-25T06:46:34.000Z</published>
    <updated>2023-01-12T01:15:21.514Z</updated>
    
    <content type="html"><![CDATA[<p>为了解决一道小学三年级的数学题，比较笨的我只能写个小程序，还好大学时学生C语言！</p><span id="more"></span><p>题目：在方框（—）里填上1-7（每个数字只用一次），使竖式成立。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/***每个方框的数字分别用一个字母代替：</span></span><br><span class="line"><span class="comment">    -e- -c- -b-</span></span><br><span class="line"><span class="comment">x           -a-</span></span><br><span class="line"><span class="comment">---------------</span></span><br><span class="line"><span class="comment">-g- -f- -d-  8</span></span><br><span class="line"><span class="comment">**************************/</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">findNum</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> a=<span class="number">1</span>; a&lt;=<span class="number">7</span>; a++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> b=<span class="number">1</span>; b&lt;=<span class="number">7</span>; b++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(a!=b)</span><br><span class="line">&#123;</span><br><span class="line">                <span class="type">int</span> product1 = a * b;  <span class="comment">//个位数</span></span><br><span class="line">                <span class="type">int</span> remainder1 = product1 % <span class="number">10</span>;</span><br><span class="line">                <span class="type">int</span> division1 = product1 / <span class="number">10</span>;</span><br><span class="line">                <span class="keyword">if</span>(remainder1 == <span class="number">8</span>)&#123;</span><br><span class="line">                    <span class="keyword">for</span>(<span class="type">int</span> c=<span class="number">1</span>;c&lt;=<span class="number">7</span>;c++)</span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="keyword">if</span>(c!=a &amp;&amp; c!=b)</span><br><span class="line">                        &#123;</span><br><span class="line">                            <span class="type">int</span> product2= c * a + division1;  <span class="comment">//十位数</span></span><br><span class="line">                            <span class="type">int</span> division2 = product2 / <span class="number">10</span>;</span><br><span class="line">                            <span class="type">int</span> d = product2 % <span class="number">10</span>;</span><br><span class="line">                            <span class="keyword">if</span>(d!=a &amp;&amp; d!=b &amp;&amp; d!=c &amp;&amp; d&gt;<span class="number">0</span> &amp;&amp; d&lt;=<span class="number">7</span>)</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="keyword">for</span> (<span class="type">int</span> e=<span class="number">1</span>;e&lt;=<span class="number">7</span>;e++)</span><br><span class="line">                                &#123;</span><br><span class="line">                                    <span class="keyword">if</span>(e!=a &amp;&amp; e!=b &amp;&amp;e!=c &amp;&amp;e!=d)</span><br><span class="line">                                    &#123;</span><br><span class="line">                                        <span class="type">int</span> product3= e * a + division2;  <span class="comment">//百位数</span></span><br><span class="line">                                        <span class="type">int</span> division3 = product3 / <span class="number">10</span>;</span><br><span class="line">                                        <span class="type">int</span> g = division3;</span><br><span class="line">                                        <span class="type">int</span> f = product3 % <span class="number">10</span>;</span><br><span class="line">                                        <span class="keyword">if</span>((f!=a &amp;&amp;f!=b &amp;&amp;f!=c &amp;&amp;f!=d &amp;&amp;f!=e &amp;&amp;f!=g &amp;&amp; f &lt;= <span class="number">7</span> &amp;&amp; f &gt; <span class="number">0</span>)&amp;&amp;(g!=a &amp;&amp;g!=b &amp;&amp;g!=c &amp;&amp;g!=d &amp;&amp;g!=e &amp;&amp; g &lt;=<span class="number">7</span> &amp;&amp; g &gt; <span class="number">0</span>))</span><br><span class="line">                                        &#123;</span><br><span class="line">                                            <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;e:&quot;</span>&lt;&lt;e&lt;&lt;<span class="string">&quot; c:&quot;</span>&lt;&lt;c&lt;&lt;<span class="string">&quot; b:&quot;</span>&lt;&lt;b&lt;&lt;<span class="built_in">endl</span>&lt;&lt;<span class="string">&quot;x    a:&quot;</span>&lt;&lt;a&lt;&lt;<span class="built_in">endl</span>&lt;&lt;<span class="string">&quot;g:&quot;</span>&lt;&lt;g&lt;&lt;<span class="string">&quot; f:&quot;</span>&lt;&lt;f&lt;&lt;<span class="string">&quot; d:&quot;</span>&lt;&lt;d&lt;&lt;<span class="built_in">endl</span>;   </span><br><span class="line">                                        &#125;</span><br><span class="line">                                    &#125;</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">findNum();</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>正确答案：<br>e:4 c:5 b:3<br>x    a:6<br>g:2 f:7 d:1</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;为了解决一道小学三年级的数学题，比较笨的我只能写个小程序，还好大学时学生C语言！&lt;/p&gt;</summary>
    
    
    
    <category term="Programming" scheme="http://blog.ligene.cn/categories/Programming/"/>
    
    
  </entry>
  
  <entry>
    <title>UCSC基因组浏览器的使用</title>
    <link href="http://blog.ligene.cn/2020/09/24/GenomeBrowser/"/>
    <id>http://blog.ligene.cn/2020/09/24/GenomeBrowser/</id>
    <published>2020-09-24T04:57:05.000Z</published>
    <updated>2023-01-12T01:15:44.470Z</updated>
    
    <content type="html"><![CDATA[<p>UCSC基因组浏览器为用户提供方便查询各个物种的基因组序列，并支持对基因组信息进行可视化显示的在线工具。UCSC基因组浏览器使用注释轨道从基因组查找序列的特征，每个轨道列出基于生物学实验的特定注释，并分门别类。对于特定序列可能有数以百计的注释轨道，因此它是交互的，允许用户选择显示各种不同的注释轨道。</p><span id="more"></span><h3 id="UCSC基因组浏览器界面简介"><a href="#UCSC基因组浏览器界面简介" class="headerlink" title="UCSC基因组浏览器界面简介"></a>UCSC基因组浏览器界面简介</h3><p>在浏览器中打开UCSC基因组主页(<a href="http://genome.ucsc.edu/)%EF%BC%8C%E5%B9%B6%E7%82%B9%E5%87%BB%E8%8F%9C%E5%8D%95%E6%A0%8F%E7%9A%84Genome">http://genome.ucsc.edu/)，并点击菜单栏的Genome</a> Brower就可以看到下面界面（图1）：<br><img src="http://www.ligene.cn/images/UCSC-1.png" alt="UCSC Genome Browser"><br>图1. UCSC基因组浏览器界面</p><p> UCSC基因组浏览器页面各部分的功能介绍如上图所示: </p><ul><li>上面是导航窗口，显示染色体位置与搜索框等；导航窗口的”&gt;”或”&lt;”可以前后移动显示窗口的染色体位置，”1.5x”, “3x”等按钮可以放大缩小显示染色体内容。</li><li>中间白色背景部分是查看注释信息的显示窗口; 可以选择下面各种注释信息,每个信息都显示为一个track.</li><li>最下面除了Mapping and Sequencing（比对和序列）外，还有其它功能框：基因与预测，表型与文献，比较基因组等。每个功能框又有多个数据源，如在Genes and Gene Predictions中就包括：GENCODE、RefSeq Genes等20个数据源，每个数据源都可以单击查看说明。每个数据源显示结果可以包括hide、dense、squish、pack和full这五个不同的显示水平，按照前后顺序full是全部显示，hide为隐藏，即越靠下显示结果越多。</li></ul><h3 id="查看ALDH基因信息"><a href="#查看ALDH基因信息" class="headerlink" title="查看ALDH基因信息"></a>查看ALDH基因信息</h3><p>USCC基因组浏览器检索可以用基因名，也可以根据染色体位置检索, 如在检索框直接输入位置：chr12:111,766,922-111,817,529。这里我们以ALDH2为例，在检索框中输入ALDH2，点按钮go，在出现的页面中选择第一个条目，可以显示界面(图2):<br><img src="http://www.ligene.cn/images/UCSC-2.png" alt="UCSC基因组浏览器检索结果"><br>图2. UCSC基因组浏览器检索结果</p><p>ALDH2基因约有50,608个碱基组成，位于12号染色体q臂(染色体p臂为短臂，petite，长臂为q)，从左到右分别是5’端到3’端, 箭头代表基因转录方向。基因的exon是以box显示，而intron以线表示。末尾的UTRs是以比exon低一点的box表示。<br>通过双击track的正上方的文字说明(如“RefSeq Genes”)，track的显示会在restricted view and expanded view切换。也可以改变track的位置，把鼠标移到窗口左边的灰色按钮之上，当track颜色出现时,按住鼠标，然后拖动track到适当位置。</p><p>一般人类种群中的突变频率大于1%的单核苷酸突变称为SNPs。人类基因组中有大量SNPs，并与许多疾病或性状(traits)相关联，目前已经鉴定的SNPs都存储在公共数据库dbSNP。可以点击上图”Common SNPs track上方的文字”Simple Nucleotide Polymorphisms“来查看各个位置的SNP位点（编号以”rs”开始）。默认SNP是黑色，通过点击左边灰色按钮可以跳出一个网页来设置各种SNP的显示颜色。注意SNP位点rs671显示为红色(红色代表非同义突变)。这个SNP位点(chr12:111803962-111803962)与人类的酒精代谢能力有关, 大部分东亚人在ALDH2这个SNP有突变, 产生的乙醛脱氢酶能力只有其它人群的1&#x2F;8。</p><blockquote><p>人类基因的命名：基因符号应为大写的拉丁字母或大写的拉丁字母和阿拉伯数字的组合，基因符号应不超过6个字符，基因符号在书写时应用斜体或加下划线。如乙醛脱氢酶基因为ALDH2，胰岛素基因为INS。<br>另外，假基因(pseudogene)在基因名后加一个”P”, 如OR7E5P；还没有正式命名的基因（unchraracterized gene）直接以ORF注释命名,如 C6ORF138表示open reading frame 138 on chromosome 6。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;UCSC基因组浏览器为用户提供方便查询各个物种的基因组序列，并支持对基因组信息进行可视化显示的在线工具。UCSC基因组浏览器使用注释轨道从基因组查找序列的特征，每个轨道列出基于生物学实验的特定注释，并分门别类。对于特定序列可能有数以百计的注释轨道，因此它是交互的，允许用户选择显示各种不同的注释轨道。&lt;/p&gt;</summary>
    
    
    
    <category term="Genomics" scheme="http://blog.ligene.cn/categories/Genomics/"/>
    
    
    <category term="Tools" scheme="http://blog.ligene.cn/tags/Tools/"/>
    
  </entry>
  
  <entry>
    <title>谷歌助手使用谷歌学术</title>
    <link href="http://blog.ligene.cn/2020/04/08/ghelper/"/>
    <id>http://blog.ligene.cn/2020/04/08/ghelper/</id>
    <published>2020-04-08T13:46:29.000Z</published>
    <updated>2023-01-12T01:15:49.779Z</updated>
    
    <content type="html"><![CDATA[<p>查阅文献对于一个科研人员是必备的技能，需要经常查阅文献跟踪科研的前沿。谷歌学术(Google Scholar)是非常优秀的科学文献搜索工具，但在国内不能访问谷歌的应用。本文介绍在浏览器中安装谷歌助手(Ghelper)插件来访问Google Scholar。</p><span id="more"></span><h2 id="1-安装Edge浏览器："><a href="#1-安装Edge浏览器：" class="headerlink" title="1. 安装Edge浏览器："></a>1. 安装Edge浏览器：</h2><p>新版Edge浏览器是微软基于谷歌Chromium内核开发的全新浏览器，具有像Chrome浏览器一样的高效稳定的特点，而且能够轻松同步微软账户和打开微软应用商店下载各种插件。<br>如果Win10系统没有自动更新到新版Edge浏览器，可从微软官网下载并安装新Edge浏览器： <a href="https://www.microsoft.com/en-us/edge/">https://www.microsoft.com/en-us/edge/</a></p><blockquote><p>也可以使用Firefox浏览器。</p></blockquote><h2 id="2-安装浏览器插件Ghelper"><a href="#2-安装浏览器插件Ghelper" class="headerlink" title="2. 安装浏览器插件Ghelper:"></a>2. 安装浏览器插件Ghelper:</h2><p>谷歌上网助手(Ghelper)专门为科研、外贸、跨境电商、海淘人员、开发人员服务的上网加速工具，同时可以访问谷歌google搜索，gmail邮箱。官网为：<a href="http://googlehelper.net/%E3%80%82">http://googlehelper.net/。</a><br>使用Edge浏览器可直接从以下网址安装插件：<a href="https://microsoftedge.microsoft.com/addons/detail/eoboojokdmamahfilfmamjjkcmkmddgk?hl=zh-CN">https://microsoftedge.microsoft.com/addons/detail/eoboojokdmamahfilfmamjjkcmkmddgk?hl=zh-CN</a><br>也可从微软商店上搜索安装Ghelper: 点击Edge浏览器右上方的三个点图标，选择”Extensions”-&gt;”Get extensions from Microsoft Store”。</p><blockquote><p>Firefox也可从其设置的插件(Add-ons)管理界面中搜索安装Ghelper。</p></blockquote><h2 id="3-登录Ghelper"><a href="#3-登录Ghelper" class="headerlink" title="3. 登录Ghelper"></a>3. 登录Ghelper</h2><p>安装完成后，导航栏就会出现Ghelper图标。点击导航栏的Ghelper图标进入到登录页面，如下图所示：<br><img src="https://raw.githubusercontent.com/adong77/bigbook/master/imageBed/ghelper-1.png" alt="ghelper login"></p><p>第一次使用Ghelper要先注册一个ghelper账号，可以通过上图的新用户注册(Signup)，用任意一个邮箱注册后就可以登陆(Login)。</p><blockquote><p>注意：这个Ghelper账户不是谷歌或微软账户，不要尝试用原来的谷歌&#x2F;微软用户登录:)</p></blockquote><h2 id="4-访问谷歌学术"><a href="#4-访问谷歌学术" class="headerlink" title="4. 访问谷歌学术"></a>4. 访问谷歌学术</h2><p>登录成功后，在浏览器中输入网址：scholar.google.com，就可以使用谷歌学术搜索了。<br>你也可以安装谷歌学术的访问插件(Google Scholar Button)，只要单击一个这个插件图标就可以使用。</p><blockquote><p>使用此插件还可以访问谷歌搜索、gmail邮箱等。如果不需要使用这个插件，可以到浏览器的设置-&gt;Extensions中关闭这个插件。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;查阅文献对于一个科研人员是必备的技能，需要经常查阅文献跟踪科研的前沿。谷歌学术(Google Scholar)是非常优秀的科学文献搜索工具，但在国内不能访问谷歌的应用。本文介绍在浏览器中安装谷歌助手(Ghelper)插件来访问Google Scholar。&lt;/p&gt;</summary>
    
    
    
    <category term="Tutorials" scheme="http://blog.ligene.cn/categories/Tutorials/"/>
    
    
    <category term="Tools" scheme="http://blog.ligene.cn/tags/Tools/"/>
    
  </entry>
  
  <entry>
    <title>新冠病毒的进化树与起源分析</title>
    <link href="http://blog.ligene.cn/2020/03/19/ncov-tree/"/>
    <id>http://blog.ligene.cn/2020/03/19/ncov-tree/</id>
    <published>2020-03-18T23:31:24.000Z</published>
    <updated>2023-01-12T01:17:47.918Z</updated>
    
    <content type="html"><![CDATA[<p>根据目前的病毒序列信息，从进化树的几个问题来探讨新冠病毒的起源及其演化关系.</p><span id="more"></span><p>2019年12月在武汉爆发的新冠病毒肺炎（COVID-19），已经被世卫组织(WHO)宣布为全球大流行(pandemic)。国际病毒分类委员会(ICTV)最开始将导致COVID-19的新型冠状病毒命名为2019-nCoV，后正式命名为SARS-CoV-2，而我国部分病毒专家建议命名为HCoV-19。一个新冠病毒同时有三个英文名字，相当于我国古人的名，字，号。<br>目前关于2019-nCoV病毒的起源与可能传播途径有各种报道，众说纷纭。如果从基因组序列比对来看，还是武汉病毒所石正丽团队报道的蝙蝠病毒RaTG13与2019-nCoV序列相似度最高（96%）。后来报道的广东海关扣压的马来西亚穿山甲病毒(Guangdong1&#x2F;P2S)只有90%的相似度，不大可能为新冠病毒从蝙蝠到人传播的中间宿主。后续研究可能会发现比RaTG13序列更相似的动物源冠状病毒。<br>  但是还有一种可能性：蝙蝠病毒可以直接感染人，而不需要通过中间宿主，已经有些研究报道蝙蝠病毒只要一点改变，如Spike蛋白突变，就可以传染人类。有些这方面的研究，也使许多人认为此新冠病毒可能为人工生物合成的病毒。总之，病毒的起源还是未解之谜！</p><p>  然而，我从一些病毒专业分析网站（如<a href="https://nextstrain.org/ncov%EF%BC%89%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%EF%BC%8C%E7%9B%AE%E5%89%8D%E8%BF%9B%E5%8C%96%E6%A0%91%E9%83%BD%E6%98%AF%E4%BB%A5%E6%9D%A5%E6%AD%A6%E6%B1%89%E7%97%85%E6%AF%92%E4%B8%BA%E6%A0%B9(%E5%9B%BE1)%E3%80%82%E8%BF%99%E4%BA%9B%E8%BF%9B%E5%8C%96%E6%A0%91%E7%BB%99%E4%BA%BA%E4%B8%80%E4%B8%AA%E5%8D%B0%E8%B1%A1%E6%98%AF%E7%97%85%E6%AF%92%E6%98%AF%E4%BB%8E%E6%AD%A6%E6%B1%89%E8%B5%B7%E6%BA%90%EF%BC%8C%E5%8F%AF%E8%83%BD%E7%BE%8E%E5%9B%BD%E6%80%BB%E7%BB%9FTrump%E4%B9%9F%E6%98%AF%E7%9C%8B%E4%BA%86%E8%BF%99%E4%B8%AA%E5%9B%BE%E5%B0%B1%E8%AF%B4%E7%97%85%E6%AF%92%E6%98%AFChinese">https://nextstrain.org/ncov）可以看到，目前进化树都是以来武汉病毒为根(图1)。这些进化树给人一个印象是病毒是从武汉起源，可能美国总统Trump也是看了这个图就说病毒是Chinese</a> virus。但是这个图明显有一个问题，进化树中的节点(病毒序列)是以时间为顺序排列。这个时间是病毒被检测到并被测序的时间点，而最初测序的病毒都来自我国武汉等地区。但是病毒被测序的时间不代表是病毒的真实进化时间，这两者甚至没有关系。假如一个国家不进行病毒检测与测序，那么就不会发现新冠病毒。正如钟南山院士所说，病毒最先在武汉爆发，但不一定起源于武汉。<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/ncov_tree1.png" alt="ncov_tree1.png"><br>图1. 新冠病毒进化树 (来源<a href="https://nextstrain.org/ncov">https://nextstrain.org/ncov</a>)</p><p>  根据在生物信息学中学到的构建进化树知识，一般在不知道物种的进化亲缘关系时，进化树最好以无根(unrooted)树形式显示。目前500多株已测序的新冠病毒序列的无根树如下图所示。这个图可以预测不同病毒之间的亲缘关系，但不说明哪个病毒出现更早或更晚，即不推断祖先序列。从图2中可以看出，我国分离到的病毒序列（蓝色）都集中在上面几个分枝，而下面一大分枝并没有出现我国的病毒株；而有趣的是，分离自美国的病毒(红色)却在所有进化分枝中都存在。这说明从目前已测序的病毒序列来看，美国的病毒序列的多样性比中国的病毒更高。而多样性高一般可以作为物种起源的一个证据。例如现在科学界都认为人类起源于非洲，其中一个原因是人类基因组序列研究表明，非洲人的基因序列多样性比较高。而美国的冠状病毒的多样性高是不是可以说明新冠病毒起源于美国呢？ 当然，这是基于现在已测序的基因序列信息，随着各国病毒序列的增加，可能会有变化。<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/ncov_tree2.png" alt="ncov-tree2.png"><br>图2新冠病毒进化无根树 (来源<a href="https://www.gisaid.org/epiflu-applications/next-hcov-19-app/">https://www.gisaid.org/epiflu-applications/next-hcov-19-app/</a>)</p><p>  学习生物信息学时，老师一般会说要确定一个进化树的根部，要利用一个与所分析物种亲缘关系比较远的物种作为外群(outgroup)来确定树根。我们知道蝙蝠病毒RaTG13是目前已知与新冠病毒最接近的序列，那么我们是不是可以以RaTG13为外群来确定新冠病毒的进化关系？通过网络查找，我没有发现以RaTG13为外群的进化树。从网站virological.org看到有一个人已经专门做了新冠病毒的进化树分析Phylogenetic analysis of nCoV-2019 genomes(<a href="http://virological.org/t/phylogenetic-analysis-of-23-ncov-2019-genomes-2020-01-23/335)%EF%BC%8C%E4%BD%86%E5%8F%AF%E6%83%9C%E4%BB%96%E6%B2%A1%E6%9C%89%E4%BB%A5RaTG13%E4%B8%BA%E5%A4%96%E7%BE%A4%E6%9E%84%E5%BB%BA%E8%BF%9B%E5%8C%96%E6%A0%91%EF%BC%8C%E8%80%8C%E6%98%AF%E4%BB%A5%E6%AD%A6%E6%B1%89%E7%97%85%E6%AF%92%E4%B8%BA%E6%A0%B9%EF%BC%88%E5%9B%BE3%EF%BC%89%E3%80%82%E4%BD%86%E4%BB%96%E5%9C%A8%E8%BF%9B%E5%8C%96%E6%A0%91%E7%9A%84%E5%9B%BE%E6%B3%A8%E4%B8%AD%E8%AF%B4%E6%98%8E%E6%A0%91%E6%A0%B9%E9%80%89%E6%AD%A6%E6%B1%89%E7%97%85%E6%AF%92%E6%98%AF%E4%BB%BB%E6%84%8F%E7%9A%84(arbitrary)%EF%BC%8C%E5%8E%9F%E8%AF%9D%E6%98%AF%E2%80%9CThe">http://virological.org/t/phylogenetic-analysis-of-23-ncov-2019-genomes-2020-01-23/335)，但可惜他没有以RaTG13为外群构建进化树，而是以武汉病毒为根（图3）。但他在进化树的图注中说明树根选武汉病毒是任意的(arbitrary)，原话是“The</a> tree is rooted using the oldest sequence but this is an arbitrary choice”。这里的最老的(oldest)序列是指最早被检测并测序的意思。<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/nCoV_phyml_tree.png" alt="nCoV_phyml_tree_20200125.png"><br>图3 Maximum likelihood tree of nCoV2019 genomes constructed using PhyML. The tree is rooted using the oldest sequence but this is an arbitrary choice. The scale bar shows the length of branch that represents 1 nucleotide change in the genome. (from <a href="http://virological.org/t/phylogenetic-analysis-of-23-ncov-2019-genomes-2020-01-23/335">http://virological.org/t/phylogenetic-analysis-of-23-ncov-2019-genomes-2020-01-23/335</a>)</p><p>  为了反映新冠病毒的进化关系，我通过GISIAD数据库（<a href="https://www.gisaid.org/%EF%BC%89%E4%B8%8B%E8%BD%BD%E9%83%A8%E5%88%86%E6%96%B0%E5%86%A0%E7%97%85%E6%AF%92%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%BA%8F%E5%88%97%EF%BC%8C%E5%8C%85%E6%8B%AC%E4%B8%AD%E5%9B%BD%E3%80%81%E7%BE%8E%E5%9B%BD%E3%80%81%E6%AC%A7%E6%B4%B2%E3%80%81%E4%BA%9A%E6%B4%B2%E3%80%81%E7%BE%8E%E6%B4%B2%E7%AD%89%E5%9B%BD%E5%AE%B6%EF%BC%8C%E7%BB%8F%E8%BF%87%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%BA%8F%E5%88%97%E6%AF%94%E5%AF%B9%EF%BC%8C%E4%BB%A5%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E6%B3%95%E6%9E%84%E5%BB%BA%E8%BF%9B%E5%8C%96%E6%A0%91%EF%BC%8C%E5%B9%B6%E4%BB%A5RaTG13%E4%B8%BA%E5%A4%96%E7%BE%A4%EF%BC%8C%E4%BB%A5MEGA-X%E6%98%BE%E7%A4%BA%E8%BF%9B%E6%A0%91(%E5%9B%BE4)%E3%80%82%E5%9B%BE%E4%B8%AD%E7%BA%A2%E8%89%B2%E4%B8%BA%E6%BA%90%E8%87%AA%E7%BE%8E%E5%9B%BD%EF%BC%88USA%EF%BC%89%E7%97%85%E4%BA%BA%E7%9A%84%E7%97%85%E6%AF%92%EF%BC%8C%E8%80%8C%E8%93%9D%E8%89%B2%E4%B8%BA%E6%BA%90%E8%87%AA%E4%B8%AD%E5%9B%BD%E4%B8%8D%E5%90%8C%E5%9C%B0%E5%8C%BA%E7%97%85%E4%BA%BA%E7%9A%84%E7%97%85%E6%AF%92%E3%80%82%E4%BB%8E%E5%9B%BE4%E4%B8%AD%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%87%BA%E9%83%A8%E5%88%86%E7%BE%8E%E5%9B%BD%E7%97%85%E6%AF%92(WA1/WA4-UW2)%E4%B8%8E%E8%9D%99%E8%9D%A0%E7%97%85%E6%AF%92RaTG13%E7%9A%84%E4%BA%B2%E7%BC%98%E5%85%B3%E7%B3%BB%E6%9B%B4%E6%8E%A5%E8%BF%91%EF%BC%8C%E8%80%8C%E4%BB%8E%E6%AD%A6%E6%B1%89%E5%88%86%E7%A6%BB%E5%88%B0%E7%9A%84%E6%9C%80%E6%97%A9%E7%97%85%E6%AF%92(Wuhan-Hu-1)%E7%9B%B8%E5%AF%B9%E9%81%97%E4%BC%A0%E8%B7%9D%E7%A6%BB%E8%BE%83%E8%BF%9C%E3%80%82">https://www.gisaid.org/）下载部分新冠病毒基因组序列，包括中国、美国、欧洲、亚洲、美洲等国家，经过基因组序列比对，以最大似然法构建进化树，并以RaTG13为外群，以MEGA-X显示进树(图4)。图中红色为源自美国（USA）病人的病毒，而蓝色为源自中国不同地区病人的病毒。从图4中可以看出部分美国病毒(WA1/WA4-UW2)与蝙蝠病毒RaTG13的亲缘关系更接近，而从武汉分离到的最早病毒(Wuhan-Hu-1)相对遗传距离较远。</a> 因此，从这个进化树来看，说明冠状病毒更可能起源于美国。<br>由于受我能使用的计算机性能限制，不能把所有500多株的序列都放一起构建进化树，但这些30株病毒序列是按照图2中所有序列的分枝clade选择部分代表序列，而且去除了部分测序质量差的序列，如含许多未知碱基(N)的序列。所以还是很有代表性，增加病毒序列数量不会对树的结构有很大改变。<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/ncov_tree3.png" alt="nCoV-tree3.png"><br>图4 部分新冠病毒的进化树 （图中红色为源自美国（USA）病人的病毒，而蓝色为源自中国不同地区病人的病毒，以蝙蝠病毒RaTG13为树根并加黑显示。）</p><p>  特别需要说明的是，进化树是根据序列的差异及分子钟(molecular clock)理论来推断物种的进化关系。这个进化树中所用的新冠病毒序列之间的差异还是比较少，不到10个碱基，因此它们之间的遗传关系推断可能不准确。但是我们要强调的是，同理也不能按前面以武汉病毒为根的进化树来说病毒是起源于武汉，是吧？</p><p>  总之，根据目前的病毒序列信息，关于新冠病毒的起源及演化关系还没有定论，任何说病毒来源于武汉的言论都是没有根据的！而本文的分析结果，根据新冠病毒的序列多样性，及与蝙蝠病毒的遗传距离却说明病毒更可能来源于美国，但也需要进一步的验证，“让子弹再飞一会”。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;根据目前的病毒序列信息，从进化树的几个问题来探讨新冠病毒的起源及其演化关系.&lt;/p&gt;</summary>
    
    
    
    <category term="Bioinformatics" scheme="http://blog.ligene.cn/categories/Bioinformatics/"/>
    
    
    <category term="Tree" scheme="http://blog.ligene.cn/tags/Tree/"/>
    
  </entry>
  
  <entry>
    <title>A primer on Artificial Intelligence (AI)</title>
    <link href="http://blog.ligene.cn/2020/03/11/A-primer-on-AI/"/>
    <id>http://blog.ligene.cn/2020/03/11/A-primer-on-AI/</id>
    <published>2020-03-10T20:29:06.000Z</published>
    <updated>2023-01-12T01:13:02.953Z</updated>
    
    <content type="html"><![CDATA[<p>本文节选自英国MMC Ventures公司David Kelnar写的AI综述: <a href="https://zhuanlan.zhihu.com/p/24435190">The fourth industrial revolution: a primer on Artificial Intelligence (AI)</a></p><span id="more"></span><blockquote><p>“The last 10 years have been about building a world that is mobile-first. In the next 10 years, we will shift to a world that is AI-first.” (Sundar Pichai, CEO of Google, October 2016)</p></blockquote><h2 id="1-What-is-AI"><a href="#1-What-is-AI" class="headerlink" title="1. What is AI?"></a>1. What is AI?</h2><h3 id="Artificial-intelligence-The-science-of-intelligent-programs"><a href="#Artificial-intelligence-The-science-of-intelligent-programs" class="headerlink" title="Artificial intelligence: The science of intelligent programs"></a>Artificial intelligence: The science of intelligent programs</h3><p>Coined in 1956 by Dartmouth Assistant Professor John McCarthy, ‘Artificial Intelligence’ (AI) is a general term that refers to hardware or software that exhibits behaviour which appears intelligent. In the words of Professor McCarthy, it is “the science and engineering of making intelligent machines, especially intelligent computer programs.”<br>Basic ‘AI’ has existed for decades, via rules-based programs that deliver rudimentary displays of ‘intelligence’ in specific contexts. Progress, however, has been limited — because algorithms to tackle many real-world problems are too complex for people to program by hand.<br>Complicated activities including making medical diagnoses, predicting when machines will fail or gauging the market value of certain assets, involve thousands of data sets and non-linear relationships between variables. In these cases, it’s difficult to use the data we have to best effect — to ‘optimise’our predictions. In other cases, including recognising objects in images and translating languages, we can’t even develop rules to describe the featureswe’re looking for. How can we write a set of rules, to work in all situations, that describe the appearance of a dog?<br>What if we could transfer the difficulty of making complex predictions — the <strong>data optimisation</strong> and <strong>feature specification</strong> — from the programmer to the program? This is the promise of modern artificial intelligence.<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/AI-1.png" alt="AI-1.png"></p><h3 id="Machine-Learning-offloading-optimisation"><a href="#Machine-Learning-offloading-optimisation" class="headerlink" title="Machine Learning: offloading optimisation"></a>Machine Learning: offloading optimisation</h3><p><strong>Machine learning (ML)</strong> is a sub-set of AI. All machine learning is AI, but not all AI is machine learning (Figure 1, above). Interest in ‘AI’ today reflects enthusiasm for machine learning, where advances are rapid and significant.<br>Machine learning lets us tackle problems that are too complex for humans to solve by shifting some of the burden to the algorithm. As AI pioneer Arthur Samuel wrote in 1959, machine learning is the ‘field of study that gives computers the ability to learn without being explicitly programmed.’<br>The goal of most machine learning is to develop a prediction engine for a particular use case. An algorithm will receive information about a domain (say, the films a person has watched in the past) and weigh the inputs to make a useful prediction (the probability of the person enjoying a different film in the future). By giving ‘computers the ability to learn’, we mean passing the task of optimisation — of weighing the variables in the available data to make accurate predictions about the future — to the algorithm . Sometimes we can go further, offloading to the program the task of specifying the features to consider in the first place.<br>Machine learning algorithms learn through training. An algorithm initially receives examples whose outputs are known, notes the difference between its predictions and the correct outputs, and tunes the weightings of the inputs to improve the accuracy of its predictions until they are optimised. The defining characteristic of machine learning algorithms, therefore, is that <strong>the quality of their predictions improve with experience</strong>. The more data we provide (usually up to a point), the better the prediction engines we can create (Figures 2 and 3, below. Note that the size of data sets required are highly context dependent — we cannot generalise from the examples below.)<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/AI-2.png" alt="AI-2.png"></p><p>There are more than 15 approaches to machine learning, each of which uses a different algorithmic structure to optimise predictions based on the data received. One approach — ‘<strong>deep learning</strong>’ — is delivering breakthrough results in new domains and we explore this below. But there are many others which, although they receive less attention, are valuable because of their applicability to a broad range of usage cases. Some of the most effective machine learning algorithms beyond deep learning include:</p><ul><li>‘<strong>random forests</strong>’ that create multitudes of decision trees to optimise a prediction;</li><li>‘<strong>Bayesian networks</strong>’ that use a probabilistic approach to analyse variables and the relationships between them; and</li><li>‘<strong>support vector machines</strong>‘ that are fed categorised examples and create models to assign new inputs to one of the categories.<br>Each approach has its advantages and disadvantages and combinations may be used (an ‘<strong>ensemble</strong>’ approach). The algorithms selected to solve a particular problem will depend on factors including the nature of the available data set. In practice, developers tend to experiment to see what works.<br>Use cases of machine learning vary according to our needs and imagination. With the right data we can build algorithms for myriad purposes including: suggesting the products a person will like based on their prior purchases; anticipating when a robot on a car assembly line will fail; predicting whether an email was mis-addressed; estimating the probability of a credit card transaction being fraudulent; and many more.<h2 id="Deep-Learning-offloading-feature-specification"><a href="#Deep-Learning-offloading-feature-specification" class="headerlink" title="Deep Learning: offloading feature specification"></a>Deep Learning: offloading feature specification</h2>Even with general machine learning — random forests, Bayesian networks, support vector machines and more — it’s difficult to write programs that perform certain tasks well, from understanding speech to recognising objects in images. Why? Because we can’t specify the features to optimise in a way that’s practical and reliable. If we want to write a computer program that identifies images of cars, for example, we can’t specify the features of a car for an algorithm to process that will enable correct identification in all circumstances. Cars come in a wide range of shapes, sizes and colours. Their position, orientation and pose can differ. Background, lighting and myriad other factors impact the appearance of the object. There are too many variations to write a set of rules. Even if we could, if wouldn’t be a scalable solution. We’d need to write a program for every type of object we wanted to identify.<br>Enter deep learning (DL), which has revolutionised the world of artificial intelligence. Deep learning is a sub-set of machine learning — one of the more than 15 approaches to it. All deep learning is machine learning, but not all machine learning is deep learning (Figure 1).</li></ul><p>Deep learning is useful because it avoids the programmer having to undertake the tasks of <strong>feature specification</strong> (defining the features to analyse from the data) or <strong>optimisation</strong> (how to weigh the data to deliver an accurate prediction) — the algorithm does both.<br>How is this achieved? The breakthrough in deep learning is to model the brain, not the world. Our own brains learn to do difficult things — including understanding speech and recognising objects — not by processing exhaustive rules but through practice and feedback. As a child we experience the world (we see, for example, a picture of a car), make predictions (‘car!’) and receive feedback (‘yes!’). Without being given an exhaustive set of rules, we learn through training.<br>Deep learning uses the same approach. Artificial, software-based calculators that approximate the function of neurons in a brain are connected together. They form a ‘<strong>neural network</strong>’ which receives an input (to continue our example, a picture of a car); analyses it; makes a determination about it and is informed if its determination is correct. If the output is wrong, the connections between the neurons are adjusted by the algorithm, which will change future predictions. Initially the network will be wrong many times. But as we feed in millions of examples, the connections between neurons will be tuned so the neural network makes correct determinations on almost all occasions. Practice makes (nearly) perfect.<br>Using this process, with increasing effectiveness we can now:</p><ul><li>recognise elements in pictures;</li><li>translate between languages in real-time</li><li>use speech to control devices (via Apple’s Siri, Google Now; Amazon Alexa and Microsoft Cortana);</li><li>predict how genetic variation will effect DNA transcription;</li><li>analyse sentiment in customer reviews;</li><li>detect tumours in medical images; and more.<br>Deep learning is not well suited to every problem. It typically requires large data sets for training. It takes extensive processing power to train and run a neural network. And it has an ‘explainability’ problem — it can be difficult to know how a neural network developed its predictions. But by freeing programmers from complex feature specification, deep learning has delivered successful prediction engines for a range of important problems. As a result, it has become a powerful tool in the AI developer’s toolkit.</li></ul><h2 id="2-How-does-deep-learning-work"><a href="#2-How-does-deep-learning-work" class="headerlink" title="2. How does deep learning work?"></a>2. How does deep learning work?</h2><p>Given its importance, it’s valuable to understand the basics of how deep learning works. Deep learning involves using an artificial ‘<strong>neural network</strong>’ — a collection of ‘neurons’ (software-based calculators) connected together.</p><p>An artificial neuron has one or more inputs. It performs a mathematical calculation based on these to deliver an output. The output will depend on both the ‘<strong>weights</strong>’ of each input and the configuration of ‘input-output function’ in the neuron (Figure 5, below). The input-output function can vary. A neuron may be:</p><ul><li>a <strong>linear unit</strong> (the output is proportional to the total weighted input;</li><li>a <strong>threshold unit</strong> (the output is set to one of two levels, depending on whether the total input is above a specified value); </li><li>a <strong>sigmoid unit</strong> (the output varies continuously, but not linearly as the input changes).</li></ul><p>A neural network is created when neurons are connected to one another; the output of one neuron becomes an input for another (Figure 6, below).<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/AI-6.png" alt="AI-6.png"></p><p>Neural networks are organised into multiple layers of neurons (hence ‘deep’ learning). The ‘input layer’ receives information the network will process — for example, a set of pictures. The ‘output layer’ provides the results. Between the input and output layers are ‘hidden layers’ where most activity occurs. Typically, the outputs of each neuron on one level of the neural network serve as one of the inputs for each of the neurons in the next layer (Figure 7, below).<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/AI-7.png" alt="AI-7.png"></p><p>Let’s consider the example of an image recognition algorithm — say, to recognise human faces in pictures. When data are fed into the neural network, the first layers identify patterns of local contrast — ‘low level’ features such as edges. As the image traverses the network, progressively ‘higher level’ features are extracted — from edges to noses, from noses to faces (Fig. 8, below)<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/imageBed/AI-8.png" alt="AI-8.png"></p><p>At its output layer, based on its training the neural network will deliver a probability that the picture is of the specified type (human face: 97%; balloon 2%; leaf 1%).</p><p>Typically, neural networks are trained by exposing them to a large number of labelled examples. Errors are detected and the weights of the connections between the neurons tuned by the algorithm to improve results. The optimisation process is extensively repeated, after which the system is deployed and unlabelled images are assessed.</p><p>The above is a simple neural network but their structure can vary and most are more complex. Variations include connections between neurons on the same layer; differing numbers of neurons per layer; and the connection of neuron outputs into the previous levels of the network (‘recursive’ neural networks).</p><p>Designing and improving a neural network requires considerable skill. Steps include structuring the network for a particular application, providing a suitable training set of data, adjusting the structure of the network according to progress, and combining multiple approaches.</p><h2 id="5-What-happens-next"><a href="#5-What-happens-next" class="headerlink" title="5. What happens next?"></a>5. What happens next?</h2><p>The benefits of machine learning will be numerous and significant. Many will be visible, from autonomous vehicles to new methods of human-computer interaction. Many will be less apparent, but enable more capable and efficient day-to-day business processes and consumer services.<br>As with any paradigm shift, at times inflated expectations will exceed short-term potential. We expect a period of disillusionment regarding AI at some point in the future, to be followed by a longer and lasting recognition of its value as machine learning is used to improve and then reimagine existing systems.<br>Historically, industrial revolutions transformed production and communication through new sources of power and transmission. The first industrial revolution used steam power to mechanise production in the 1780s. The second used electricity to drive mass production in the 1870s. The third used electronics and software to automate production and communication from the 1970s. Today, as software eats the world, our primary source of value creation is the processing of information. By enabling us to do so more intelligently, machine learning will yield benefits both humble and historic.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文节选自英国MMC Ventures公司David Kelnar写的AI综述: &lt;a href=&quot;https://zhuanlan.zhihu.com/p/24435190&quot;&gt;The fourth industrial revolution: a primer on Artificial Intelligence (AI)&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Statistics" scheme="http://blog.ligene.cn/categories/Statistics/"/>
    
    
    <category term="AI" scheme="http://blog.ligene.cn/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>科学上网简易方法</title>
    <link href="http://blog.ligene.cn/2019/06/09/SetupVPN/"/>
    <id>http://blog.ligene.cn/2019/06/09/SetupVPN/</id>
    <published>2019-06-09T05:22:55.000Z</published>
    <updated>2023-01-12T01:19:44.299Z</updated>
    
    <content type="html"><![CDATA[<p>如果你不能打开一些国外的网址，如google，那么就需要科(翻)学(墙)上网了。SetupVPN(或Hoxx)是一个简单易用的免费工具。SetupVPN&#x2F;Hoxx插件适用于浏览器Chrome或Firefox，此处介绍使用Firefox与SetupVPN。</p><span id="more"></span><h2 id="1-获取一个Firefox拓展程序"><a href="#1-获取一个Firefox拓展程序" class="headerlink" title="1.获取一个Firefox拓展程序"></a>1.获取一个Firefox拓展程序</h2><p>在地址栏输入<a href="http://69.28.91.10/%EF%BC%8C%E4%BC%9A%E5%87%BA%E7%8E%B0%E5%A6%82%E4%B8%8B%E9%A1%B5%E9%9D%A2%EF%BC%9A">http://69.28.91.10/，会出现如下页面：</a><br><img src="https://raw.githubusercontent.com/adong77/LIGENE/master/imageBed/setupVPN-1.png" alt="SetupVPN-1"><br>请按照红圈依次点击，找到Firefox的拓展程序文件setupvpn_lifetime_free_vpn-3.5.3-fx.xpi（或其它版本文件），按鼠标右键在弹出菜单选择“链接另存为”，下载这个文件。</p><h2 id="2-安装Firefox的拓展程序"><a href="#2-安装Firefox的拓展程序" class="headerlink" title="2.安装Firefox的拓展程序"></a>2.安装Firefox的拓展程序</h2><p>在Firefox地址栏中输入about:addons，打开拓展程序界面。只要把刚刚下载的.xpi文件拖入这个界面里，并在弹出的安装确认选项中选择添加(Add)按钮就OK了。<br><img src="https://raw.githubusercontent.com/adong77/LIGENE/master//imageBed/setupVPN-2.png" alt="SetupVPN-2"></p><h2 id="3-注册并使用SetupVPN扩展程序"><a href="#3-注册并使用SetupVPN扩展程序" class="headerlink" title="3.注册并使用SetupVPN扩展程序"></a>3.注册并使用SetupVPN扩展程序</h2><p>安装成功后，就在Firefox浏览器右上角可以看到一个云状图标。首次点击SetupVPN图标需要用一个邮箱注册新账户，并通过邮件激活帐户，后续也不会有垃圾邮件。<br><img src="https://raw.githubusercontent.com/adong77/LIGENE/master/imageBed/setupVPN-3.png" alt="SetupVPN-3"><br>注册帐户登录后，可以在下方免费服务器里选择一个国家，建议选择日本，会比较快一点。建立连接后即可开始畅游外面的世界。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;如果你不能打开一些国外的网址，如google，那么就需要科(翻)学(墙)上网了。SetupVPN(或Hoxx)是一个简单易用的免费工具。SetupVPN&amp;#x2F;Hoxx插件适用于浏览器Chrome或Firefox，此处介绍使用Firefox与SetupVPN。&lt;/p&gt;</summary>
    
    
    
    <category term="Tutorials" scheme="http://blog.ligene.cn/categories/Tutorials/"/>
    
    
    <category term="Tools" scheme="http://blog.ligene.cn/tags/Tools/"/>
    
  </entry>
  
  <entry>
    <title>Windows系统下16S rDNA扩增子数据分析流程</title>
    <link href="http://blog.ligene.cn/2019/06/08/win16s-pipeline/"/>
    <id>http://blog.ligene.cn/2019/06/08/win16s-pipeline/</id>
    <published>2019-06-08T13:51:37.000Z</published>
    <updated>2023-01-12T01:20:24.967Z</updated>
    
    <content type="html"><![CDATA[<p>本16S rRNA基因扩增子测序数据分析流程包括：首先对样本测序数据进行质控与预处理；然后得到样本的OTU聚类与物种分类信息；在查看样品的细菌种类后，统计每个样品的差异菌种。For more details about 16S rRNA analysis, recommend following the tutorial: <a href="https://rachaellappan.github.io/16S-analysis/index.html">https://rachaellappan.github.io/16S-analysis/index.html</a><br>Please note that QIIME1 and the 97% OTU-based workflow has been superseded by ASVs (100% OTUs) and the QIIME2 workflow! </p><span id="more"></span><h3 id="1-流程相关软件安装"><a href="#1-流程相关软件安装" class="headerlink" title="1. 流程相关软件安装"></a>1. 流程相关软件安装</h3><p>本分析流程需要在Windows的Linux子系统(WSL)下安装QIIME、VSEARCH等软件。</p><ul><li><p>安装Linux常用工具</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$sudo apt-get install build-essential#Linux基础开发工具</span><br><span class="line">$sudo apt-get install python-minimal python-dev python-tk </span><br><span class="line">$sudo apt-get install python-pip  #可用pip安装python包</span><br><span class="line">$python --version</span><br><span class="line">#如果python不是python2.7，请设置python2为默认版本：alias python=’/usr/bin/python2’(可把此命令写入~/.bashrc文件中)。</span><br></pre></td></tr></table></figure></li><li><p>安装QIIME</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$sudo pip install --upgrade pip -i http://mirrors.aliyun.com/pypi/simple --trusted-host mirrors.aliyun.com</span><br><span class="line">$sudo pip install numpy==1.10.0 -i http://mirrors.aliyun.com/pypi/simple --trusted-host mirrors.aliyun.com</span><br><span class="line">$sudo pip install matplotlib==1.5.3 -i http://mirrors.aliyun.com/pypi/simple --trusted-host mirrors.aliyun.com</span><br><span class="line">$sudo pip install scipy==1.0.0 -i http://mirrors.aliyun.com/pypi/simple --trusted-host mirrors.aliyun.com</span><br><span class="line">$sudo pip install ipython==5.5.0 -i http://mirrors.aliyun.com/pypi/simple --trusted-host mirrors.aliyun.com</span><br><span class="line">sudo pip install pandas==0.21.1 -i http://mirrors.aliyun.com/pypi/simple --trusted-host mirrors.aliyun.com</span><br><span class="line">$sudo pip install qiime -i http://mirrors.aliyun.com/pypi/simple --trusted-host mirrors.aliyun.com</span><br><span class="line"></span><br><span class="line">#测序QIIME安装是否成功</span><br><span class="line">$print_qiime_config.py -t</span><br></pre></td></tr></table></figure></li><li><p>安装VSEARCH</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$git clone https://github.com/torognes/vsearch.git</span><br><span class="line">$cd vsearch</span><br><span class="line">$./autogen.sh</span><br><span class="line">$./configure</span><br><span class="line">$make</span><br><span class="line">$sudo make install  #默认安装在/usr/local/bin/目录</span><br><span class="line">$sudo cp /usr/local/bin/vsearch /usr/local/bin/usearch61 #让qiime的参数usearch61使用vsearch程序</span><br></pre></td></tr></table></figure></li><li><p>安装ClustalW<br><code>$sudo apt-get install clustalw</code></p></li><li><p>安装RDP classifier</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#1.下载RDP Classifier v2.2(只有此版本能用)，下载网址：https://sourceforge.net/projects/rdp-classifier/files/rdp-classifier/</span><br><span class="line">#2.解压到windows系统的D盘根目录，并复制到Ubuntu系统的用户home目录：</span><br><span class="line">$mv /mnt/d/rdp_classifier_2.2/  ~/</span><br><span class="line">$echo &quot;export RDP_JAR_PATH=~/rdp_classifier_2.2/rdp_classifier-2.2.jar&quot; &gt;&gt; ~/.bashrc</span><br><span class="line">$source ~/.bashrc</span><br></pre></td></tr></table></figure></li><li><p>安装Xming可运行X-windows图形程序</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#下载安装包Xming-setup.exe（最新版本6.9.0.31），Xming官网：http://sourceforge.net/projects/xming/</span><br><span class="line">$echo &quot;export DISPLAY=:0.0&quot; &gt;&gt; ~/.bashrc #设置X图形显示端口</span><br><span class="line">$source ~/.bashrc</span><br></pre></td></tr></table></figure></li></ul><h3 id="2-流程运行命令"><a href="#2-流程运行命令" class="headerlink" title="2. 流程运行命令"></a>2. 流程运行命令</h3><p>此流程所有命令都需在WSL-Ubuntu的bash终端下运行（以下命令前面的“$”代表bash提示符，不需要输入）。运行Ubuntu之前，先在电脑C盘创建目录win16s，并将样本测序数据文件(raw_reads.zip)，mapping.txt，参考序列文件(rdp_gold.fa)与参数设置文件(qiime_params.txt)复制到此目录下。<br>注意：所有输入文件名及目录，根据自己保存的文件进行调整。</p><h4 id="1-准备测序数据-raw-reads"><a href="#1-准备测序数据-raw-reads" class="headerlink" title="(1)准备测序数据(raw reads)"></a>(1)准备测序数据(raw reads)</h4><p>本实验需要把所有原始数据放在一个文件夹，一个样品的双端测序有两个reads文件，默认以”_R1”与”_R2”分别代表正向与反向测序reads。测序公司提供的数据一般已去除barcode和primer序列。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$cd /mnt/c/ch17rRNA/#切换到工作目录</span><br><span class="line">$unzip raw_reads.zip</span><br><span class="line">$ls raw_reads</span><br><span class="line">显示文件列表，如SAA_R1.fastq.gz, SAA_R2.fastq.gz等，如果文件名不对，需要重新命名。</span><br></pre></td></tr></table></figure><h4 id="2-准备mapping-file"><a href="#2-准备mapping-file" class="headerlink" title="(2)准备mapping file"></a>(2)准备mapping file</h4><p>mapping文件必须的列名如下：<br><code>#sampleID    BarcodeSequence    LinkerPrimerSequence    Description</code><br>注意：每项之间不能出现空格, 间隔是以TAB键隔开。如果没有BarcodeSequence与LinkerPrimerSequennce信息可以为空。<br>LinkerPrimerSequence与Description之间可以有任意项来说明样本的额外信息。如要修改可用Excel打开mapping.txt，按样本名称修改，再保存为txt格式即可。<br>本测序数据样本mapping file式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#SampleIDBarcodeSequenceLinkerPrimerSequence    PRIMERGroupDescription</span><br><span class="line">SAAACGAGTGCGTAGAGTTTGATCMTGGCTC 8FdietSAA</span><br><span class="line">SABAGACGCACTCAGAGTTTGATCMTGGCTC 8FfatSAB</span><br></pre></td></tr></table></figure><p>这里SampleID项对应于前面测序reads文件名的前三个字母， Group是样本的分组信息, PRIMER是16S引物名称。<br>修改mapping.txt后执行以下命令检查是否有问题：<br><code>$validate_mapping_file.py -m mapping.txt -o validate_map</code><br>在Wiondows资源管理器下打开输出目录validate_map中的mapping.html文件查看检查信息，并根据错误提示修改mapping文件。如果没有BarcodeSequence与LinkerPrimerSequennce信息，可忽略Barcode与Primer序列为空的错误提示。</p><h4 id="3-合并双端序列"><a href="#3-合并双端序列" class="headerlink" title="(3)合并双端序列"></a>(3)合并双端序列</h4><p>如果样品数量较小，可以对每个样品分别进行合并，一次合并一个样品的两端测序数据：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$mkdir  join_pe_reads</span><br><span class="line">$vsearch --fastq_mergepairs raw_reads/SAA_R1.fastq.gz --reverse raw_reads/SAA_R2.fastq.gz --fastqout join_pe_reads/SAA.fq</span><br><span class="line">Merging reads 100%</span><br><span class="line">     28741  Pairs</span><br><span class="line">     19633  Merged (68.3%)</span><br><span class="line">      9108  Not merged (31.7%)</span><br></pre></td></tr></table></figure><p>如果样品数量较多，也可用以下shell脚本一次合并多个样品数据：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$for i in `tail -n+2 mapping.txt |cut -f 1`; do vsearch --fastq_mergepairs raw_reads/$&#123;i&#125;_R1.fastq.gz --reverse raw_reads/$&#123;i&#125;_R2.fastq.gz --fastqout join_pe_reads/$&#123;i&#125;.fq ; done</span><br></pre></td></tr></table></figure><h4 id="4-序列质量控制"><a href="#4-序列质量控制" class="headerlink" title="(4)序列质量控制"></a>(4)序列质量控制</h4><p>一般可先用FastQC检查测序reads的质量信息，注意测序reads长度。16S rRNA v3-v4区片段大约为400bp左右，这里将合并后reads长度&lt; 380 bp的reads都过滤掉。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$mkdir qual_filter</span><br><span class="line">$vsearch --fastx_filter join_pe_reads/SAA.fq --fastq_maxee 1.0 --fastq_minlen 380 --fastqout join_pe_reads/SAA_filter.fq</span><br></pre></td></tr></table></figure><p>如果有多个样品数据，可直接copy下面命令到terminal执行：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$for i in `tail -n+2 mapping.txt |cut -f 1`; do vsearch --fastx_filter join_pe_reads/$&#123;i&#125;.fq --fastq_maxee 1.0 --fastq_minlen 380 --fastqout qual_filter/$&#123;i&#125;.fq ; done</span><br></pre></td></tr></table></figure><h4 id="5-割库-split-libraries"><a href="#5-割库-split-libraries" class="headerlink" title="(5)割库(split libraries)"></a>(5)割库(split libraries)</h4><p>此步骤将所有样本的序列数据合并成到一个文件，并以样品名区分样品序列。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$mkdir split_out</span><br><span class="line">$multiple_split_libraries_fastq.py -i qual_filter/ -o split_out/ --demultiplexing_method sampleid_by_file</span><br></pre></td></tr></table></figure><p>输出文件为 seqs.fna，每条序列的ID按来源的样品重命名，头行还包括纠正barcode错误(bc_diffs)等信息。<br>此命令运行的概要信息可以查看输出文件split_library_log.txt，包含样品的reads数量，低质量reads过滤结果等。</p><h4 id="6-Dereplication-序列去重复"><a href="#6-Dereplication-序列去重复" class="headerlink" title="(6)Dereplication(序列去重复)"></a>(6)Dereplication(序列去重复)</h4><p><code>$vsearch --derep_fulllength split_out/seqs.fna --output split_out/seqs_derep.fa --sizeout --minuniquesize 2</code></p><h4 id="7-嵌合体检测"><a href="#7-嵌合体检测" class="headerlink" title="(7)嵌合体检测"></a>(7)嵌合体检测</h4><p>嵌合子的产生主要是由于PCR过程中模版的不完全延伸。这一步是去除嵌合子，一般需要参考序列文件：<br><code>$vsearch --uchime_ref split_out/seqs_derep.fa --db rdp_gold.fa --nonchimeras seqs_nochimeras.fa </code><br>如果没有参考序列，VSEARCH也可以进行去嵌合体：<br><code>$vsearch --uchime_denovo split_out/seqs_derep.fa --nonchimeras seqs_nochimeras.fa</code></p><h4 id="8-OTU聚类-OTU-clustering"><a href="#8-OTU聚类-OTU-clustering" class="headerlink" title="(8)OTU聚类(OTU clustering)"></a>(8)OTU聚类(OTU clustering)</h4><p>OTU (operational taxonomic units)是人为给某一个分类单元(科、属、种等)设置的标志。通常按照97%的相似性阈值将序列划分为不同的OTU，每一个OTU通常被认为是一个微生物物种。选取最长的序列作为OTU的代表。<br><code>$vsearch --cluster_fast seqs_nochimeras.fa --id 0.97 --centroids otus.fa --relabel OTU_</code><br>以序列最小相似度97%聚类，得到Clusters: 121</p><h4 id="9-物种分类注释"><a href="#9-物种分类注释" class="headerlink" title="(9)物种分类注释"></a>(9)物种分类注释</h4><p>QIIME 采用RDP classifier 将OUT注释为不同物种分类。<br><code>$assign_taxonomy.py -i otus.fa -m rdp -o taxonomy</code><br>注意：分类数据库可以采用GreenGenes (<a href="http://greengenes.secondgenome.com/)%E3%80%81Silva">http://greengenes.secondgenome.com/)、Silva</a> (<a href="https://www.arb-silva.de/)%E5%92%8CRDP">https://www.arb-silva.de/)和RDP</a> (<a href="http://rdp.cme.msu.edu/)%E3%80%82%E8%BF%99%E9%87%8C%E9%87%87%E7%94%A8Ribosomal">http://rdp.cme.msu.edu/)。这里采用Ribosomal</a> Database Project classifier与Greengenes 数据库（13_8版本）。 </p><h4 id="10-生成OTU表格"><a href="#10-生成OTU表格" class="headerlink" title="(10)生成OTU表格"></a>(10)生成OTU表格</h4><ul><li><ol><li>Map reads back to the OTU data：<br><code>$vsearch --usearch_global split_out/seqs.fna --db otus.fa --strand plus --id 0.97 --otutabout otus_table.txt</code></li></ol></li><li><ol start="2"><li>Convert otu_table.txt to otu-table.biom<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$biom convert -i otus_table.txt -o otus_table.biom --to-hdf5 --table-type &quot;OTU table&quot;</span><br><span class="line">$biom add-metadata -i otus_table.biom -o otus_table_tax.biom --observation-metadata-fp taxonomy/otus_tax_assignments.txt --sc-separated taxonomy --observation-header OTUID,taxonomy</span><br></pre></td></tr></table></figure></li></ol></li><li><p>也可以用QIIME的脚本生成OTU表：<br><code>make_otu_table.py -i otus_table.txt -t taxonomy/otus_tax_assignments.txt -o otus_table1.biom</code></p></li></ul><h4 id="11-检查OTU-Table"><a href="#11-检查OTU-Table" class="headerlink" title="(11)检查OTU Table"></a>(11)检查OTU Table</h4><p><code>$biom summarize-table -i otus_table_tax.biom -o summary_biom.txt</code><br>记录样本测序数据量最少的read Counts数(此处为Min：11640），用于后续的统计抽样（步骤15中的-e参数）。</p><ul><li>关于OTU表的更多检查问题参见后面注释(Notes)部分。</li></ul><p>16S数据一般有许多noise，如嵌合体序列，低丰度的OTUs等。<br>我们只过滤低频率的OTUs，过滤的标准是OTU总数在每个样品中都低于2(-min_count 2)，而且任何OTU只在少于25%的样品中有(-min_samples 3):</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$filter_otus_from_otu_table.py -i otus_table_tax.biom -o otus_table_tax_filtered.biom  --min_count 2</span><br><span class="line">#查看还剩下多少OTU？</span><br><span class="line">$biom summarize-table -i otus_table_tax_filtered.biom</span><br><span class="line">//Num observations: 199</span><br></pre></td></tr></table></figure><p>注意如果发现有什么错误，可以先用Excel打开otu_table_tsv.txt修改，然后再转换成biom格式。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$biom convert -i otus_table_tax.biom -o otus_table_tsv.txt --table-type &quot;OTU table&quot; --to-tsv --header-key taxonomy</span><br><span class="line">$biom convert -i otus_table_tsv.txt  -o otus_table_tsv.biom --table-type &quot;OTU table&quot; --to-hdf5 --table-type=&quot;OTU table&quot; --process-obs-metadata taxonomy</span><br></pre></td></tr></table></figure><h4 id="12-可视化"><a href="#12-可视化" class="headerlink" title="(12)可视化"></a>(12)可视化</h4><p>运行可视化命令前，电脑要先运行Xming软件。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#Plot relative abundance for all samples</span><br><span class="line">$summarize_taxa_through_plots.py -i otus_table_tax.biom -m mapping.txt -o taxa_summary</span><br></pre></td></tr></table></figure><p>输出文件存放在目录taxa_summary，其中图形信息放在目录taxa_summary_plots，可用浏览器打开bar_charts.html文件查看各个样本自门水平(L2)到属水平(L6)分类水平的菌株组成分布信息。<br>从上到下分别列出5个分类水平门到属的柱状图，每个柱状图下面是对应的数据表，表中分类(Taxonomy)的字母分别代表不同分类水平：k&#x3D;kingdom, p&#x3D;phylum, c&#x3D;class, o&#x3D;order, f&#x3D;family, g&#x3D;genus.<br><img src="https://raw.githubusercontent.com/adong77/ligene/master/Images/book/taxa_plots.png" alt="taxa_bar_plots.png"><br>图 1 样品的菌群分类与相对丰度 (A)门水平； (B)属水平</p><h4 id="13-Align-sequences-on-QIIME-using-the-ClustalW-or-muscle-method"><a href="#13-Align-sequences-on-QIIME-using-the-ClustalW-or-muscle-method" class="headerlink" title="(13) Align sequences on QIIME using the ClustalW or muscle method"></a>(13) Align sequences on QIIME using the ClustalW or muscle method</h4><p><code>$align_seqs.py -i otus.fa -m clustalw -o rep_set_align</code></p><h4 id="14-Make-the-reference-tree-on-QIIME"><a href="#14-Make-the-reference-tree-on-QIIME" class="headerlink" title="(14) Make the reference tree on QIIME"></a>(14) Make the reference tree on QIIME</h4><p><code>$make_phylogeny.py -i rep_set_align/otus_aligned.fasta -o rep_set.tre</code></p><h4 id="15-多样性分析-Run-diversity-analyses-on-QIIME"><a href="#15-多样性分析-Run-diversity-analyses-on-QIIME" class="headerlink" title="(15)多样性分析(Run diversity analyses on QIIME)"></a>(15)多样性分析(Run diversity analyses on QIIME)</h4><p>多样性分析有Alpha diversity与Beta diversity。<br><code>$core_diversity_analyses.py -i otus_table_tax.biom -m mapping.txt -t rep_set.tre -e 10000 -o core_diversity -p qiime_params.txt</code><br>参数“-e 10000”是用于均匀抽样和最大稀疏(rarefaction)深度的测序深度。由于测序技术的原因，不同样品的数据量有差异，因此不同的样品数据要先随机从每个样品中选择相同数目的reads (rarefy the data)进行标准化处理后才能进行样品间的比较。</p><p>下面列举几个特殊的分析命令：</p><ul><li><ol><li>Making PCoA plots:<br><code>$make_2d_plots.py -i core_diversity/bdiv_even11640/weighted_unifrac_pc.txt -o pcoa_plot -m mapping.txt -b Group</code><br>注：-i参数后输入文件所在目录的数字（11640）会随前面命令的-e参数变化。</li></ol></li><li><ol start="2"><li>统计两组间的菌群差异：<br><code>$compare_categories.py --method anosim -i core_diversity/bdiv_even11640/weighted_unifrac_dm.txt -m mapping.txt -c Group -o anosim_out -n 99</code></li></ol></li></ul><hr><h3 id="3-Notes："><a href="#3-Notes：" class="headerlink" title="3. Notes："></a>3. Notes：</h3><ul><li><ol><li>16S数据一般有许多noise，如嵌合体序列，低丰度的OTUs等。<br>下面的命令只过滤低频率的OTUs，过滤的标准是OTU总数在每个样品中都低于2(-min_count 2)，而且任何OTU只在少于25%的样品中有(-min_samples 3):<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$filter_otus_from_otu_table.py -i otus_table_tax.biom -o otus_table_tax_filtered.biom  --min_count 2</span><br><span class="line">#查看还剩下多少OTU？</span><br><span class="line">$biom summarize-table -i otus_table_tax_filtered.biom</span><br><span class="line">//Num observations: 199</span><br></pre></td></tr></table></figure></li></ol></li><li><ol start="2"><li>注意：如果发现有什么错误，可以先将biom文件转换成文本文件，再用Excel打开otu_table_tsv.txt修改，然后再转换成biom格式。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$biom convert -i otus_table_tax.biom -o otus_table_tsv.txt --table-type &quot;OTU table&quot; --to-tsv --header-key taxonomy</span><br><span class="line">$biom convert -i otus_table_tsv.txt  -o otus_table_tsv.biom --table-type &quot;OTU table&quot; --to-hdf5 --table-type=&quot;OTU table&quot; --process-obs-metadata taxonomy</span><br></pre></td></tr></table></figure></li></ol></li></ul><p><strong>For more details about 16S rRNA analysis</strong>, recommend following the tutorial: <a href="https://rachaellappan.github.io/16S-analysis/index.html">https://rachaellappan.github.io/16S-analysis/index.html</a> </p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本16S rRNA基因扩增子测序数据分析流程包括：首先对样本测序数据进行质控与预处理；然后得到样本的OTU聚类与物种分类信息；在查看样品的细菌种类后，统计每个样品的差异菌种。For more details about 16S rRNA analysis, recommend following the tutorial: &lt;a href=&quot;https://rachaellappan.github.io/16S-analysis/index.html&quot;&gt;https://rachaellappan.github.io/16S-analysis/index.html&lt;/a&gt;&lt;br&gt;Please note that QIIME1 and the 97% OTU-based workflow has been superseded by ASVs (100% OTUs) and the QIIME2 workflow! &lt;/p&gt;</summary>
    
    
    
    <category term="Genomics" scheme="http://blog.ligene.cn/categories/Genomics/"/>
    
    
    <category term="WSL" scheme="http://blog.ligene.cn/tags/WSL/"/>
    
    <category term="QIIME" scheme="http://blog.ligene.cn/tags/QIIME/"/>
    
  </entry>
  
  <entry>
    <title>Windows下连接远程Linux桌面</title>
    <link href="http://blog.ligene.cn/2018/01/25/Xming-PuTTY/"/>
    <id>http://blog.ligene.cn/2018/01/25/Xming-PuTTY/</id>
    <published>2018-01-25T00:45:16.000Z</published>
    <updated>2023-01-12T01:20:49.767Z</updated>
    
    <content type="html"><![CDATA[<p>一般我们是通过命令行界面来使用Linux服务器，但有时也需要用Linux图形界面的软件，如IGV。当需要显示的基因组信息比较大，如测序reads的基因组比对情况，会占用大量内存，在服务器上运行会比较流畅。下面是本地windows电脑显示远程Linux服务器桌面的方法。</p><span id="more"></span><h2 id="1-Windows安装Xming"><a href="#1-Windows安装Xming" class="headerlink" title="1. Windows安装Xming"></a>1. Windows安装Xming</h2><p>从SourceForge下载Xming-setup.exe（最新的版本是6.9.0.31）。<br>Xming的SourceForge网址： <a href="http://sourceforge.net/projects/xming/">http://sourceforge.net/projects/xming/</a><br>本地安装，安装过程一切按默认选项。<br>第一次运行时，找到开始菜单里面的XLaunch来启动，产生一个初始的配置文件。对于简单的使用来说，不需要任何特殊的配置，使用默认即可。<br>下图中选择“one window”，设置“Display number”中的数字为0。<br><img src="https://raw.githubusercontent.com/adong77/LIGENE/master/imageBed/Xming.png" alt="Xming Setup"><br>  启动完成后，在任务栏右边会出现一个“X”形状的图标，这表示Xming已经在运行了，将鼠标悬停上去，能看到当前使用的“Display number”使用默认的0.0。</p><h2 id="2-Linux服务器配置"><a href="#2-Linux服务器配置" class="headerlink" title="2. Linux服务器配置"></a>2. Linux服务器配置</h2><p> 修改ssh服务的配置文件：<br><code>$vi /etc/ssh/sshd_config</code><br>取消下面一行的注释，如果没有这一行则手动添加：<br>X11Forwrding yes<br>这样配置的作用就是允许SSH的X转发。</p><h2 id="3-PuTTY设置"><a href="#3-PuTTY设置" class="headerlink" title="3. PuTTY设置"></a>3. PuTTY设置</h2><p>SSH客户端使用PuTTY，PuTTY是freeware+greenware。<br>PuTTY下载网址：<a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html</a><br>配置 Session：配置linux服务器IP，连接方式为SSH<br>Connection &gt; Data：保存连接使用的用户名<br>Connection &gt; SSH &gt; X11：Enable X11 Forwarding，X display Location 为 “localhost:0”，这里的 0 就是配置 Xming X server 时指定的 Display Number。<br>保存设置：选Session，Saved sessions输入一个名称，并按右边Save按钮。每次更改PuTTY设置都需要这样保存，下次Load这个Session才是同样的设置。<br><img src="https://raw.githubusercontent.com/adong77/LIGENE/master/imageBed/putty.png" alt="putty Setup"><br> 至此配置完成。<br>在windows上使用PuTTY连接到Linux服务器，输入xclock &amp;，可以看到X server工作效果了，显示一个时钟图形界面。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;一般我们是通过命令行界面来使用Linux服务器，但有时也需要用Linux图形界面的软件，如IGV。当需要显示的基因组信息比较大，如测序reads的基因组比对情况，会占用大量内存，在服务器上运行会比较流畅。下面是本地windows电脑显示远程Linux服务器桌面的方法。&lt;/p&gt;</summary>
    
    
    
    <category term="Tutorials" scheme="http://blog.ligene.cn/categories/Tutorials/"/>
    
    
    <category term="Xming" scheme="http://blog.ligene.cn/tags/Xming/"/>
    
    <category term="PuTTY" scheme="http://blog.ligene.cn/tags/PuTTY/"/>
    
  </entry>
  
  <entry>
    <title>编程语言之C语言</title>
    <link href="http://blog.ligene.cn/2018/01/05/clang/"/>
    <id>http://blog.ligene.cn/2018/01/05/clang/</id>
    <published>2018-01-05T00:25:23.000Z</published>
    <updated>2023-01-12T01:15:11.458Z</updated>
    
    <content type="html"><![CDATA[<p>C语言是一门通用的计算机编程语言，广泛应用于系统与应用软件的开发。它是由Dennis Ritchie与Ken Thompson于1969年至1973年间，为了移植与开发UNIX操作系统，在贝尔实验室设计与开发。C语言具有高效、灵活、功能丰富、表达力强和可移植性好等特点。C语言的设计影响了众多后来的编程语言，例如C++、Objective-C、Java、C#等。</p><span id="more"></span><p>C语言后来发展出多种版本，如Microsoft C、Turbo C等。为了避免各开发商的C语言语法产生差异，美国国家标准研究所(ANSI)为C语言制定了一套国际标准语法，简称为ANSI C。二十世纪八十年代至今的相关程序开发工具，一般都支持匹配ANSI C的语法。目前，C语言编译器普遍存在于各种不同的操作系统中，例如Microsoft Windows, Mac OS X, Linux等。Windows系统下常用的C语言编译器有Microsoft Visual C&#x2F;C++；Linux系统下常用的编译器是GCC(GNU C编译器)等。<br>由于Linux系统也是由C语言开发，其上运行的许多应用软件都由C语言开发，所以我们要对C语言编程有一点了解，才能做好数据分析所需软件的安装工作。<strong>一般Linux开源软件的开发者会提供C语言编写的源代码，如果有些软件安装出问题，可以通过阅读源代码来解决。</strong><br>###C语言程序开发<br>C语言是编译性的高级语言，运行之前需要用编译工具将源代码编译链接成目标文件和可执行文件。C语言编程过程大致可分为四步：编写程序 -&gt; 编译 -&gt; 链接 -&gt; 运行。</p><ul><li><p>(1) 编写源代码<br>一个 C 语言程序源代码，可以是 3 行，也可以是数百万行。它可以写在一个或多个扩展名为 “.c” 的文本文件中，例如hello.c。您可以使用文本编辑器notepad、vim等来编写C语言程序。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">void main()</span><br><span class="line">&#123;</span><br><span class="line">printf(&quot;Hello World!&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>(2) 用编译工具编译，并链接生成可执行文件<br><code>$gcc -o helloworld hello.c</code><br> &#x2F;&#x2F;编译并链接生成可执行文件helloworld</p><blockquote><p>如果c程序有多个源代码文件，可能先分别编译成相应的中间目标文件，最后将所有中间文件链接成一个可执行文件。这样其中一个源文件改动后，不用所有文件都要重新编译。Linux提供自动维护工具make，运行make可以从makefile中读取模块之间的关系，自动维护与更新程序的修改。<br><code>$gcc -c hello.c</code><br>&#x2F;&#x2F;只编译生成中间文件hello.o</p></blockquote></li><li><p>(3) 运行helloworld可执行文件<br><code>$./helloworld</code><br>&#x2F;&#x2F;输出”Hello World!”。</p></li></ul><p><img src="https://raw.githubusercontent.com/adong77/LIGENE/master/imageBed/cprogramming.png" alt="C programming"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;C语言是一门通用的计算机编程语言，广泛应用于系统与应用软件的开发。它是由Dennis Ritchie与Ken Thompson于1969年至1973年间，为了移植与开发UNIX操作系统，在贝尔实验室设计与开发。C语言具有高效、灵活、功能丰富、表达力强和可移植性好等特点。C语言的设计影响了众多后来的编程语言，例如C++、Objective-C、Java、C#等。&lt;/p&gt;</summary>
    
    
    
    <category term="Programming" scheme="http://blog.ligene.cn/categories/Programming/"/>
    
    
    <category term="C" scheme="http://blog.ligene.cn/tags/C/"/>
    
  </entry>
  
</feed>
